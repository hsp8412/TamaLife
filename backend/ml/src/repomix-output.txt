This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-02-16T11:29:22.232Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

================================================================
Directory Structure
================================================================
api_lite.py
api.py
convert_to_tflite.py
dataset.py
model.py
organize_dataset.py
test_api.py
test_model_webcam.py
test_model.py
train.py

================================================================
Files
================================================================

================
File: api_lite.py
================
# backend/ml/src/api_lite.py
import tensorflow as tf
import numpy as np
from PIL import Image
import json
import sys

CATEGORIES = ["non_food", "food", "junk_food"]


def load_and_process_image(image_path):
    img = Image.open(image_path)
    img = img.resize((224, 224))
    img_array = np.array(img) / 255.0
    img_array = np.expand_dims(img_array, 0)
    return img_array.astype(np.float32)


def main():
    if len(sys.argv) != 2:
        print(json.dumps({"error": "Image path not provided"}))
        sys.exit(1)

    try:
        # Load TFLite model using TensorFlow
        interpreter = tf.lite.Interpreter(model_path="../model/model_latest.tflite")
        interpreter.allocate_tensors()

        # Get input/output details
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()

        # Process image
        image_path = sys.argv[1]
        input_data = load_and_process_image(image_path)

        # Set input tensor
        interpreter.set_tensor(input_details[0]["index"], input_data)

        # Run inference
        interpreter.invoke()

        # Get output tensor
        predictions = interpreter.get_tensor(output_details[0]["index"])[0]
        predicted_class = np.argmax(predictions)
        confidence = float(predictions[predicted_class])

        # Prepare response
        result = {
            "category": CATEGORIES[predicted_class],
            "confidence": confidence,
            "all_probabilities": {
                cat: float(prob) for cat, prob in zip(CATEGORIES, predictions)
            },
        }

        print(json.dumps(result))

    except Exception as e:
        print(json.dumps({"error": f"Prediction failed: {str(e)}"}))
        sys.exit(1)


if __name__ == "__main__":
    main()

================
File: api.py
================
import sys
import json
import tensorflow as tf
import numpy as np
from PIL import Image

# Define categories
CATEGORIES = ["non_food", "food", "junk_food"]


def load_model():
    # Load the model from the relative path
    model_path = "../model/model_latest.h5"
    try:
        return tf.keras.models.load_model(model_path)
    except Exception as e:
        print(json.dumps({"error": f"Failed to load model: {str(e)}"}))
        sys.exit(1)


def preprocess_image(image_path):
    try:
        # Open and preprocess the image
        image = Image.open(image_path)
        image = image.resize((224, 224))
        image = np.array(image) / 255.0
        image = np.expand_dims(image, axis=0)
        return image
    except Exception as e:
        print(json.dumps({"error": f"Failed to process image: {str(e)}"}))
        sys.exit(1)


def main():
    if len(sys.argv) != 2:
        print(json.dumps({"error": "Image path not provided"}))
        sys.exit(1)

    image_path = sys.argv[1]

    # Load model
    model = load_model()

    # Process image
    processed_image = preprocess_image(image_path)

    try:
        # Make prediction
        predictions = model.predict(processed_image)[0]
        predicted_class = np.argmax(predictions)
        confidence = float(predictions[predicted_class])

        # Prepare response
        result = {
            "category": CATEGORIES[predicted_class],
            "confidence": confidence,
            "all_probabilities": {
                cat: float(prob) for cat, prob in zip(CATEGORIES, predictions)
            },
        }

        # Print result as JSON string
        print(json.dumps(result))

    except Exception as e:
        print(json.dumps({"error": f"Prediction failed: {str(e)}"}))
        sys.exit(1)


if __name__ == "__main__":
    main()

================
File: convert_to_tflite.py
================
# backend/ml/src/convert_to_tflite_simple.py
import tensorflow as tf
import os


def convert_model_simple():
    try:
        # Load your existing model
        print("Loading model...")
        model_path = "../model/model_latest.h5"
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"Model file not found at {model_path}")

        model = tf.keras.models.load_model(model_path)
        print("Model loaded successfully")

        # Create a concrete function from the model
        print("Creating concrete function...")
        input_shape = model.input_shape
        concrete_func = tf.function(model).get_concrete_function(
            tf.TensorSpec(input_shape, tf.float32)
        )

        # Convert using from_concrete_functions
        print("Converting model...")
        converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])

        # Basic settings
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]

        tflite_model = converter.convert()

        # Save the converted model
        output_path = "../model/model_latest.tflite"
        with open(output_path, "wb") as f:
            f.write(tflite_model)

        print(f"Model converted successfully and saved to {output_path}")
        print(
            f"Original model size: {os.path.getsize(model_path) / (1024*1024):.2f} MB"
        )
        print(f"TFLite model size: {os.path.getsize(output_path) / (1024*1024):.2f} MB")

    except Exception as e:
        print(f"Error during conversion: {str(e)}")
        raise


if __name__ == "__main__":
    print("Starting model conversion...")
    convert_model_simple()

================
File: dataset.py
================
# dataset.py
import tensorflow as tf
import os
import numpy as np
from typing import Tuple, Dict


class FoodDataset:
    def __init__(
        self,
        data_dir: str,
        img_size: Tuple[int, int] = (224, 224),
        batch_size: int = 32,
    ):
        """
        Initialize FoodDataset with enhanced preprocessing and validation

        Args:
            data_dir: Root directory of the dataset
            img_size: Target size for images (height, width)
            batch_size: Batch size for training
        """
        self.data_dir = data_dir
        self.img_size = img_size
        self.batch_size = batch_size
        self.categories = ["non_food", "healthy_food", "unhealthy_food"]

    def _parse_image(
        self, filename: tf.Tensor, label: tf.Tensor
    ) -> Tuple[tf.Tensor, tf.Tensor]:
        """
        Enhanced image parsing with robust augmentation and preprocessing
        """
        # Convert filename to string
        filename = tf.cast(filename, tf.string)
        label = tf.cast(label, tf.int32)

        # Read and decode image
        image = tf.io.read_file(filename)
        image = tf.image.decode_jpeg(image, channels=3)

        # Enhanced data augmentation pipeline
        image = tf.cast(image, tf.float32)

        # Random augmentations for training diversity
        image = tf.image.random_brightness(image, 0.2)
        image = tf.image.random_contrast(image, 0.8, 1.2)
        image = tf.image.random_saturation(image, 0.8, 1.2)
        image = tf.image.random_hue(image, 0.1)
        image = tf.image.random_flip_left_right(image)

        # 50% chance of additional augmentations
        if tf.random.uniform([]) > 0.5:
            image = tf.image.transpose(image)
            image = tf.image.random_flip_up_down(image)

        # Center crop before resize for consistent aspect ratio
        shape = tf.shape(image)
        min_dim = tf.minimum(shape[0], shape[1])
        image = tf.image.resize_with_crop_or_pad(image, min_dim, min_dim)

        # Resize to target size
        image = tf.image.resize(image, self.img_size)

        # Normalize pixel values
        image = tf.clip_by_value(image, 0.0, 255.0)
        image = image / 255.0

        # Convert label to one-hot encoding
        label = tf.one_hot(label, 3)

        return image, label

    def create_dataset(self, split: str = "training") -> tf.data.Dataset:
        """
        Create dataset with enhanced error handling and logging
        """
        split_dir = os.path.join(self.data_dir, split)

        # Initialize containers
        image_files = []
        labels = []
        category_counts = {category: 0 for category in self.categories}

        # Process each category
        for label, category in enumerate(self.categories):
            category_dir = os.path.join(split_dir, category)

            if not os.path.exists(category_dir):
                print(f"Warning: Directory not found: {category_dir}")
                continue

            # Get all valid image files
            valid_files = [
                os.path.join(category_dir, f)
                for f in os.listdir(category_dir)
                if f.lower().endswith((".jpg", ".jpeg", ".png"))
            ]

            category_counts[category] = len(valid_files)
            image_files.extend(valid_files)
            labels.extend([label] * len(valid_files))

        # Print dataset statistics
        print(f"\nDataset statistics for {split}:")
        print("-" * 50)
        for category, count in category_counts.items():
            print(f"{category}: {count} images")
        print(f"Total: {sum(category_counts.values())} images")

        # Verify dataset is not empty
        if not image_files:
            raise ValueError(f"No images found in {split_dir}")

        # Create TensorFlow dataset
        dataset = tf.data.Dataset.from_tensor_slices(
            (tf.constant(image_files), tf.constant(labels, dtype=tf.int32))
        )

        # Configure dataset for performance
        dataset = dataset.map(self._parse_image, num_parallel_calls=tf.data.AUTOTUNE)

        if split == "training":
            # Shuffle training data with larger buffer
            dataset = dataset.shuffle(
                buffer_size=min(50000, len(image_files)), reshuffle_each_iteration=True
            )

        # Optimize performance
        dataset = dataset.batch(self.batch_size).prefetch(tf.data.AUTOTUNE).cache()

        return dataset

    def get_class_weights(self, split: str = "training") -> Dict[int, float]:
        """
        Calculate balanced class weights with improved handling of edge cases
        """
        split_dir = os.path.join(self.data_dir, split)

        # Count images in each class
        counts = {}
        for i, category in enumerate(self.categories):
            category_dir = os.path.join(split_dir, category)
            if os.path.exists(category_dir):
                counts[i] = len(
                    [
                        f
                        for f in os.listdir(category_dir)
                        if f.lower().endswith((".jpg", ".jpeg", ".png"))
                    ]
                )
            else:
                counts[i] = 0
                print(f"Warning: Directory not found: {category_dir}")

        # Calculate total samples
        total_samples = sum(counts.values())
        if total_samples == 0:
            raise ValueError(f"No images found in {split_dir}")

        # Calculate balanced weights
        n_classes = len(self.categories)
        weights = {}
        for class_idx, count in counts.items():
            if count == 0:
                weights[class_idx] = 1.0
            else:
                weights[class_idx] = total_samples / (n_classes * count)

        # Print weight distribution
        print(f"\nClass weights for {split}:")
        for i, category in enumerate(self.categories):
            print(f"{category}: {weights[i]:.4f}")

        return weights

    def validate_dataset(self) -> None:
        """
        Validate dataset integrity and balance
        """
        for split in ["training", "validation", "evaluation"]:
            split_dir = os.path.join(self.data_dir, split)
            if not os.path.exists(split_dir):
                print(f"Warning: Split directory not found: {split_dir}")
                continue

            total_images = 0
            corrupted_images = 0

            for category in self.categories:
                category_dir = os.path.join(split_dir, category)
                if not os.path.exists(category_dir):
                    print(f"Warning: Category directory not found: {category_dir}")
                    continue

                # Check each image
                for img_name in os.listdir(category_dir):
                    if not img_name.lower().endswith((".jpg", ".jpeg", ".png")):
                        continue

                    total_images += 1
                    img_path = os.path.join(category_dir, img_name)

                    try:
                        with tf.io.gfile.GFile(img_path, "rb") as fid:
                            image_data = fid.read()
                            _ = tf.image.decode_jpeg(image_data, channels=3)
                    except tf.errors.InvalidArgumentError:
                        print(f"Corrupted image found: {img_path}")
                        corrupted_images += 1

            print(f"\nDataset validation results for {split}:")
            print(f"Total images: {total_images}")
            print(f"Corrupted images: {corrupted_images}")

================
File: model.py
================
import tensorflow as tf
from tensorflow.keras import layers, models


def create_model(input_shape=(224, 224, 3)):
    # Base model (MobileNetV2)
    base_model = tf.keras.applications.MobileNetV2(
        input_shape=input_shape, include_top=False, weights="imagenet"
    )

    # Freeze the base model
    base_model.trainable = False

    # Create new model with 3 output classes
    model = models.Sequential(
        [
            base_model,
            layers.GlobalAveragePooling2D(),
            layers.Dense(128, activation="relu"),
            layers.Dropout(0.2),
            layers.Dense(3, activation="softmax"),  # Changed to 3 outputs with softmax
        ]
    )

    # Compile the model
    model.compile(
        optimizer="adam",
        loss="categorical_crossentropy",  # Use categorical_crossentropy for multi-class
        metrics=["accuracy"],
    )

    return model


def create_model_with_fine_tuning(input_shape=(224, 224, 3), fine_tune_layers=30):
    # Base model (MobileNetV2)
    base_model = tf.keras.applications.MobileNetV2(
        input_shape=input_shape, include_top=False, weights="imagenet"
    )

    # Freeze early layers
    base_model.trainable = True
    for layer in base_model.layers[:-fine_tune_layers]:
        layer.trainable = False

    # Create new model with 3 output classes
    model = models.Sequential(
        [
            base_model,
            layers.GlobalAveragePooling2D(),
            layers.Dense(256, activation="relu"),
            layers.Dropout(0.3),
            layers.Dense(128, activation="relu"),
            layers.Dropout(0.2),
            layers.Dense(3, activation="softmax"),  # Three categories
        ]
    )

    # Compile with a lower learning rate for fine-tuning
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
        loss="categorical_crossentropy",
        metrics=["accuracy"],
    )

    return model


def get_model_summary(model):
    """Get model architecture summary"""
    trainable_params = tf.keras.backend.count_params(
        tf.concat([tf.reshape(w, [-1]) for w in model.trainable_weights], axis=0)
    )
    non_trainable_params = tf.keras.backend.count_params(
        tf.concat([tf.reshape(w, [-1]) for w in model.non_trainable_weights], axis=0)
    )

    print("\nModel Summary:")
    print(f"Total parameters: {trainable_params + non_trainable_params:,}")
    print(f"Trainable parameters: {trainable_params:,}")
    print(f"Non-trainable parameters: {non_trainable_params:,}")

    return {
        "total_params": trainable_params + non_trainable_params,
        "trainable_params": trainable_params,
        "non_trainable_params": non_trainable_params,
    }

================
File: organize_dataset.py
================
# organize_dataset.py
import os
import shutil
from pathlib import Path

# Define healthy and unhealthy categories from Food-101 Data Set
HEALTHY_FOODS = [
    "beef_carpaccio",
    "beef_tartare",
    "beet_salad",
    "bibimbap",
    "caesar_salad",
    "caprese_salad",
    "ceviche",
    "chicken_curry",
    "edamame",
    "eggs_benedict",
    "falafel",
    "fried_rice",
    "gnocchi",
    "greek_salad",
    "grilled_salmon",
    "gyoza",
    "huevos_rancheros",
    "lasagna",
    "miso_soup",
    "mussels",
    "omelette",
    "pad_thai",
    "paella",
    "pancakes",
    "pho",
    "ramen",
    "risotto",
    "sashimi",
    "scallops",
    "seaweed_salad",
    "shrimp_and_grits",
    "spring_rolls",
    "steak",
    "sushi",
    "tuna_tartare",
    "waffles",
]

UNHEALTHY_FOODS = [
    "apple_pie",
    "baby_back_ribs",
    "baklava",
    "beignets",
    "bread_pudding",
    "breakfast_burrito",
    "cannoli",
    "carrot_cake",
    "cheesecake",
    "chicken_wings",
    "chocolate_cake",
    "chocolate_mousse",
    "churros",
    "croque_madame",
    "cup_cakes",
    "donuts",
    "french_fries",
    "fried_calamari",
    "hamburger",
    "hot_dog",
    "ice_cream",
    "macaroni_and_cheese",
    "macarons",
    "nachos",
    "onion_rings",
    "pizza",
    "poutine",
    "red_velvet_cake",
]


def create_hybrid_dataset():
    # Define paths and output to our hybrid_dataset (combination of the two)
    food101_path = "../data/food-101/images"
    food5k_path = "../data/Food-5k"
    output_path = "../data/hybrid_dataset"

    # Create directory structure
    for split in ["training", "validation", "evaluation"]:
        os.makedirs(os.path.join(output_path, split, "healthy_food"), exist_ok=True)
        os.makedirs(os.path.join(output_path, split, "non_food"), exist_ok=True)
        os.makedirs(os.path.join(output_path, split, "unhealthy_food"), exist_ok=True)

    # Copy non-food images from Food-5K
    for split in ["training", "validation", "evaluation"]:
        src_dir = os.path.join(food5k_path, split, "non_food")
        dst_dir = os.path.join(output_path, split, "non_food")

        print(f"Copying non-food images from {split} set...")
        for img in os.listdir(src_dir):
            if img.endswith(".jpg"):
                shutil.copy2(os.path.join(src_dir, img), os.path.join(dst_dir, img))

    # Copy and categorize food images from Food-101
    total_images_per_category = 1000  # Adjust this number as needed

    print("\nCopying healthy food images from Food-101...")
    for category in HEALTHY_FOODS:
        category_path = os.path.join(food101_path, category)
        if not os.path.exists(category_path):
            print(f"Warning: Category {category} not found")
            continue

        images = [f for f in os.listdir(category_path) if f.endswith(".jpg")]
        images = images[:total_images_per_category]

        # Calculate split sizes
        num_images = len(images)
        train_size = int(num_images * 0.7)
        val_size = int(num_images * 0.15)

        # Split images
        train_images = images[:train_size]
        val_images = images[train_size : train_size + val_size]
        test_images = images[train_size + val_size :]

        # Copy to respective splits in healthy_food directory
        for split_info in [
            ("training", train_images),
            ("validation", val_images),
            ("evaluation", test_images),
        ]:
            split_name, split_images = split_info
            for img in split_images:
                shutil.copy2(
                    os.path.join(category_path, img),
                    os.path.join(
                        output_path, split_name, "healthy_food", f"{category}_{img}"
                    ),
                )

    print("\nCopying unhealthy food images from Food-101...")
    for category in UNHEALTHY_FOODS:
        # Same process for unhealthy foods
        category_path = os.path.join(food101_path, category)
        if not os.path.exists(category_path):
            print(f"Warning: Category {category} not found")
            continue

        images = [f for f in os.listdir(category_path) if f.endswith(".jpg")]
        images = images[:total_images_per_category]

        num_images = len(images)
        train_size = int(num_images * 0.7)
        val_size = int(num_images * 0.15)

        train_images = images[:train_size]
        val_images = images[train_size : train_size + val_size]
        test_images = images[train_size + val_size :]

        # Copy to respective splits in unhealthy_food directory
        for split_info in [
            ("training", train_images),
            ("validation", val_images),
            ("evaluation", test_images),
        ]:
            split_name, split_images = split_info
            for img in split_images:
                shutil.copy2(
                    os.path.join(category_path, img),
                    os.path.join(
                        output_path, split_name, "unhealthy_food", f"{category}_{img}"
                    ),
                )

    # Print final dataset statistics
    print("\nFinal Dataset Statistics:")
    for split in ["training", "validation", "evaluation"]:
        healthy_count = len(
            os.listdir(os.path.join(output_path, split, "healthy_food"))
        )
        non_food_count = len(os.listdir(os.path.join(output_path, split, "non_food")))
        unhealthy_count = len(
            os.listdir(os.path.join(output_path, split, "unhealthy_food"))
        )
        print(f"\n{split.capitalize()} set:")
        print(f"Healthy food images: {healthy_count}")
        print(f"Non-food images: {non_food_count}")
        print(f"Unhealthy food images: {unhealthy_count}")
        print(f"Total: {healthy_count + non_food_count + unhealthy_count}")


if __name__ == "__main__":
    print("Creating hybrid dataset...")
    create_hybrid_dataset()
    print("\nDone!")

================
File: test_api.py
================
# test_api.py
import tensorflow as tf
import numpy as np
from PIL import Image
import os


def load_and_preprocess_image(image_path):
    """Load and preprocess a single image"""
    img = Image.open(image_path)
    img = img.resize((224, 224))
    img_array = np.array(img) / 255.0
    img_array = np.expand_dims(img_array, 0)
    return img_array


def test_images():
    """Test model predictions on test images"""
    # Categories
    CATEGORIES = ["non_food", "food", "junk_food"]

    # Load model
    print("Loading model...")
    model_path = "../model/model_latest.h5"
    try:
        model = tf.keras.models.load_model(model_path)
    except Exception as e:
        print(f"Error loading model: {e}")
        return

    # Test directory
    test_dir = "../test_images"
    test_images = sorted(
        [f for f in os.listdir(test_dir) if f.endswith((".jpg", ".jpeg"))]
    )

    print("\nTesting images...")
    print("=" * 50)

    results = []
    for image_name in test_images:
        image_path = os.path.join(test_dir, image_name)
        try:
            # Process image
            img_array = load_and_preprocess_image(image_path)

            # Get predictions
            predictions = model.predict(img_array, verbose=0)[0]
            predicted_class = np.argmax(predictions)
            confidence = predictions[predicted_class]

            # Store results
            result = {
                "image": image_name,
                "predicted": CATEGORIES[predicted_class],
                "confidence": confidence,
                "probabilities": {
                    cat: float(prob) for cat, prob in zip(CATEGORIES, predictions)
                },
            }
            results.append(result)

            # Print results
            print(f"\nImage: {image_name}")
            print(f"Predicted: {result['predicted']}")
            print(f"Confidence: {confidence:.4f}")
            print("Probabilities:")
            for cat, prob in result["probabilities"].items():
                print(f"  {cat}: {prob:.4f}")
            print("-" * 50)

        except Exception as e:
            print(f"Error processing {image_name}: {e}")

    # Print summary
    print("\nSummary:")
    for category in CATEGORIES:
        count = sum(1 for r in results if r["predicted"] == category)
        print(f"{category}: {count} images")


if __name__ == "__main__":
    test_images()

================
File: test_model_webcam.py
================
import tensorflow as tf
import cv2
import numpy as np
import os
import sys


def load_and_preprocess_frame(frame):
    resized = cv2.resize(frame, (224, 224))
    rgb = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)
    normalized = rgb / 255.0
    batched = np.expand_dims(normalized, 0)
    return batched


def main():
    # Load the trained model
    print("Loading model...")
    model_path = "../model_latest.h5"
    if not os.path.exists(model_path):
        print(f"Error: Model not found at {model_path}")
        sys.exit(1)

    model = tf.keras.models.load_model(model_path)

    # Category labels and colors
    CATEGORIES = ["NOT FOOD", "HEALTHY FOOD", "UNHEALTHY FOOD"]
    COLORS = [
        (0, 0, 255),  # Red for NOT FOOD
        (0, 255, 0),  # Green for HEALTHY FOOD
        (0, 165, 255),  # Orange for UNHEALTHY FOOD (BGR format)
    ]

    print("Starting webcam...")
    cap = cv2.VideoCapture(0)

    # Check if camera opened successfully
    if not cap.isOpened():
        print("\nError: Could not open camera")
        print(
            "Please check your camera permissions in System Settings > Privacy & Security > Camera"
        )
        print("Make sure Terminal/Python has permission to access the camera")
        sys.exit(1)

    print("Camera accessed successfully!")
    print("Press 'q' to quit")

    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                print("Failed to grab frame")
                break

            processed_frame = load_and_preprocess_frame(frame)
            predictions = model.predict(processed_frame, verbose=0)[0]
            predicted_class = np.argmax(predictions)
            confidence = predictions[predicted_class]

            # Get all probabilities
            probabilities = {cat: prob for cat, prob in zip(CATEGORIES, predictions)}

            # Prepare text display
            text = CATEGORIES[predicted_class]
            confidence_text = f"Confidence: {confidence:.2f}"

            # Additional probabilities text
            prob_texts = [f"{cat}: {prob:.2f}" for cat, prob in probabilities.items()]

            # Background rectangle for text (make it larger for all probabilities)
            cv2.rectangle(frame, (10, 10), (300, 110), (0, 0, 0), -1)

            # Add main prediction and confidence
            cv2.putText(
                frame,
                text,
                (20, 35),
                cv2.FONT_HERSHEY_SIMPLEX,
                1,
                COLORS[predicted_class],
                2,
            )
            cv2.putText(
                frame,
                confidence_text,
                (20, 60),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.7,
                (255, 255, 255),
                2,
            )

            # Add all probabilities
            y_offset = 85
            cv2.putText(
                frame,
                f"All: {' | '.join(prob_texts)}",
                (20, y_offset),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.4,
                (255, 255, 255),
                1,
            )

            cv2.imshow("Food Detector", frame)

            if cv2.waitKey(1) & 0xFF == ord("q"):
                print("\nQuitting...")
                break

    except KeyboardInterrupt:
        print("\nInterrupted by user")
    except Exception as e:
        print(f"\nAn error occurred: {str(e)}")
    finally:
        cap.release()
        cv2.destroyAllWindows()


if __name__ == "__main__":
    main()

================
File: test_model.py
================
# test_model.py
import tensorflow as tf
import numpy as np
from PIL import Image
import os
import random


def load_and_preprocess_image(image_path):
    # Load image
    img = Image.open(image_path)
    # Resize to match model's expected input
    img = img.resize((224, 224))
    # Convert to array and normalize
    img_array = np.array(img) / 255.0
    # Add batch dimension
    img_array = np.expand_dims(img_array, 0)
    return img_array


def test_model():
    # Load the trained model
    print("Loading model...")
    model = tf.keras.models.load_model("../model_final.h5")

    # Print model summary
    print("\nModel Summary:")
    model.summary()

    # Paths for evaluation set
    eval_dir = "../data/hybrid_dataset/evaluation"
    healthy_food_dir = os.path.join(eval_dir, "healthy_food")
    non_food_dir = os.path.join(eval_dir, "non_food")
    unhealthy_food_dir = os.path.join(eval_dir, "unhealthy_food")

    # Get 5 random images from each category
    healthy_food_images = random.sample(
        [f for f in os.listdir(healthy_food_dir) if f.endswith(".jpg")], 5
    )
    non_food_images = random.sample(
        [f for f in os.listdir(non_food_dir) if f.endswith(".jpg")], 5
    )
    unhealthy_food_images = random.sample(
        [f for f in os.listdir(unhealthy_food_dir) if f.endswith(".jpg")], 5
    )

    categories = ["Non-Food", "Healthy Food", "Unhealthy Food"]

    def test_category(images, directory, category_name):
        print(f"\nTesting {category_name} Images:")
        print("=" * 50)
        for img_name in images:
            img_path = os.path.join(directory, img_name)
            img_array = load_and_preprocess_image(img_path)
            predictions = model.predict(img_array, verbose=0)[0]

            predicted_class = np.argmax(predictions)
            confidence = predictions[predicted_class]

            print(f"\nImage: {img_name}")
            print(f"Prediction: {categories[predicted_class]}")
            print(f"Confidence: {confidence:.4f}")
            print("All probabilities:")
            for cat, prob in zip(categories, predictions):
                print(f"  {cat}: {prob:.4f}")
            print("-" * 50)

    # Test all categories
    test_category(healthy_food_images, healthy_food_dir, "Healthy Food")
    test_category(non_food_images, non_food_dir, "Non-Food")
    test_category(unhealthy_food_images, unhealthy_food_dir, "Unhealthy Food")


if __name__ == "__main__":
    print("Testing model on all three categories...")
    test_model()

================
File: train.py
================
# train.py
import tensorflow as tf
from tensorflow.keras import layers, models
from dataset import FoodDataset
import os
import shutil


def ensure_directories():
    """Create necessary directories for model saving"""
    # Create both src/checkpoints and checkpoints directories
    directories = ["checkpoints", "src/checkpoints"]
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
        print(f"Created directory: {directory}")


def save_model_with_verification(model, base_path, filename):
    """Save model and verify it exists in both locations"""
    # Save to primary location
    primary_path = os.path.join(base_path, filename)
    model.save(primary_path)
    print(f"Model saved to: {primary_path}")

    # Copy to src/checkpoints for compatibility
    src_path = os.path.join("src/checkpoints", filename)
    shutil.copy2(primary_path, src_path)
    print(f"Model copied to: {src_path}")

    return primary_path, src_path


def train():
    # Configuration
    DATA_DIR = "../data/hybrid_dataset"
    IMG_SIZE = (224, 224)
    BATCH_SIZE = 32
    EPOCHS = 15

    # Ensure directories exist
    ensure_directories()

    print(f"Loading data from: {os.path.abspath(DATA_DIR)}")

    # Create datasets
    dataset = FoodDataset(DATA_DIR, IMG_SIZE, BATCH_SIZE)
    train_ds = dataset.create_dataset("training")
    val_ds = dataset.create_dataset("validation")

    # Get class weights
    class_weights = dataset.get_class_weights("training")
    print("\nClass weights:", class_weights)

    # Create model
    print("\nCreating model...")
    model = models.Sequential(
        [
            tf.keras.applications.MobileNetV2(
                input_shape=(*IMG_SIZE, 3), include_top=False, weights="imagenet"
            ),
            layers.GlobalAveragePooling2D(),
            layers.Dense(256, activation="relu"),
            layers.Dropout(0.4),
            layers.Dense(128, activation="relu"),
            layers.Dropout(0.3),
            layers.Dense(3, activation="softmax"),
        ]
    )

    # Compile model
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
        loss="categorical_crossentropy",
        metrics=["accuracy"],
    )

    # Callbacks
    callbacks = [
        tf.keras.callbacks.ModelCheckpoint(
            filepath="checkpoints/best_model.h5",
            save_best_only=True,
            monitor="val_accuracy",
            mode="max",
            verbose=1,
        ),
        tf.keras.callbacks.EarlyStopping(
            monitor="val_accuracy", patience=5, restore_best_weights=True
        ),
        tf.keras.callbacks.ReduceLROnPlateau(
            monitor="val_loss", factor=0.2, patience=3, min_lr=1e-6
        ),
    ]

    # Train model
    print("\nStarting training...")
    history = model.fit(
        train_ds,
        validation_data=val_ds,
        epochs=EPOCHS,
        callbacks=callbacks,
        class_weight=class_weights,
        verbose=1,
    )

    # Save final model with verification
    print("\nSaving final model...")
    try:
        primary_path, src_path = save_model_with_verification(
            model, "checkpoints", "model.h5"
        )
        print(f"Model successfully saved and verified at:")
        print(f"1. {primary_path}")
        print(f"2. {src_path}")
    except Exception as e:
        print(f"Error saving model: {str(e)}")

    return history, model


if __name__ == "__main__":
    print("Starting training process...")
    try:
        history, model = train()

        # Verify saved model exists
        expected_paths = ["checkpoints/model.h5", "src/checkpoints/model.h5"]
        for path in expected_paths:
            if os.path.exists(path):
                print(f"Verified: Model exists at {path}")
            else:
                print(f"Warning: Model not found at {path}")

    except Exception as e:
        print(f"Error during training: {str(e)}")
