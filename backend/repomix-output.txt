This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-02-16T11:00:59.106Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

================================================================
Directory Structure
================================================================
middleware/
  auth.ts
ml/
  src/
    api.py
    dataset.py
    model.py
    organize_dataset.py
    test_api.py
    test_model_webcam.py
    test_model.py
    train.py
  requirements.txt
models/
  user.ts
repos/
  foodRepo.ts
  stateRepo.ts
  userRepo.ts
routes/
  auth.ts
  food.ts
  ml.ts
  pet.ts
  state.ts
services/
  llmService.ts
startup/
  db.ts
  routes.ts
tests/
  llm-pet-test.js
  llm-test.ts
.gitignore
index.ts
package.json

================================================================
Files
================================================================

================
File: middleware/auth.ts
================
import jwt from "jsonwebtoken";

export const auth = (req, res, next) => {
  // Try to get token from cookies first (for web clients)
  let token = req.cookies?.jwt_token;

  // If not found, check Authorization header (for React Native)
  if (!token && req.headers.authorization) {
    const authHeader = req.headers.authorization;
    if (authHeader.startsWith("Bearer ")) {
      token = authHeader.split(" ")[1]; // Extract token from Bearer scheme
    }
  }

  if (!token) {
    return res.status(401).json({error: "Access denied. No token provided."});
  }

  const jwtPrivateKey = process.env.JWT_PRIVATE_KEY;
  if (!jwtPrivateKey) {
    return res.status(500).json({error: "JWT private key is not defined."});
  }

  try {
    const decoded = jwt.verify(token, jwtPrivateKey);
    req.user = decoded;
    next();
  } catch (ex) {
    res.status(400).json({error: "Invalid token."});
  }
};

================
File: ml/src/api.py
================
import sys
import json
import tensorflow as tf
import numpy as np
from PIL import Image

# Define categories
CATEGORIES = ["non_food", "food", "junk_food"]


def load_model():
    # Load the model from the relative path
    model_path = "../model/model_latest.h5"
    try:
        return tf.keras.models.load_model(model_path)
    except Exception as e:
        print(json.dumps({"error": f"Failed to load model: {str(e)}"}))
        sys.exit(1)


def preprocess_image(image_path):
    try:
        # Open and preprocess the image
        image = Image.open(image_path)
        image = image.resize((224, 224))
        image = np.array(image) / 255.0
        image = np.expand_dims(image, axis=0)
        return image
    except Exception as e:
        print(json.dumps({"error": f"Failed to process image: {str(e)}"}))
        sys.exit(1)


def main():
    if len(sys.argv) != 2:
        print(json.dumps({"error": "Image path not provided"}))
        sys.exit(1)

    image_path = sys.argv[1]

    # Load model
    model = load_model()

    # Process image
    processed_image = preprocess_image(image_path)

    try:
        # Make prediction
        predictions = model.predict(processed_image)[0]
        predicted_class = np.argmax(predictions)
        confidence = float(predictions[predicted_class])

        # Prepare response
        result = {
            "category": CATEGORIES[predicted_class],
            "confidence": confidence,
            "all_probabilities": {
                cat: float(prob) for cat, prob in zip(CATEGORIES, predictions)
            },
        }

        # Print result as JSON string
        print(json.dumps(result))

    except Exception as e:
        print(json.dumps({"error": f"Prediction failed: {str(e)}"}))
        sys.exit(1)


if __name__ == "__main__":
    main()

================
File: ml/src/dataset.py
================
# dataset.py
import tensorflow as tf
import os
import numpy as np
from typing import Tuple, Dict


class FoodDataset:
    def __init__(
        self,
        data_dir: str,
        img_size: Tuple[int, int] = (224, 224),
        batch_size: int = 32,
    ):
        """
        Initialize FoodDataset with enhanced preprocessing and validation

        Args:
            data_dir: Root directory of the dataset
            img_size: Target size for images (height, width)
            batch_size: Batch size for training
        """
        self.data_dir = data_dir
        self.img_size = img_size
        self.batch_size = batch_size
        self.categories = ["non_food", "healthy_food", "unhealthy_food"]

    def _parse_image(
        self, filename: tf.Tensor, label: tf.Tensor
    ) -> Tuple[tf.Tensor, tf.Tensor]:
        """
        Enhanced image parsing with robust augmentation and preprocessing
        """
        # Convert filename to string
        filename = tf.cast(filename, tf.string)
        label = tf.cast(label, tf.int32)

        # Read and decode image
        image = tf.io.read_file(filename)
        image = tf.image.decode_jpeg(image, channels=3)

        # Enhanced data augmentation pipeline
        image = tf.cast(image, tf.float32)

        # Random augmentations for training diversity
        image = tf.image.random_brightness(image, 0.2)
        image = tf.image.random_contrast(image, 0.8, 1.2)
        image = tf.image.random_saturation(image, 0.8, 1.2)
        image = tf.image.random_hue(image, 0.1)
        image = tf.image.random_flip_left_right(image)

        # 50% chance of additional augmentations
        if tf.random.uniform([]) > 0.5:
            image = tf.image.transpose(image)
            image = tf.image.random_flip_up_down(image)

        # Center crop before resize for consistent aspect ratio
        shape = tf.shape(image)
        min_dim = tf.minimum(shape[0], shape[1])
        image = tf.image.resize_with_crop_or_pad(image, min_dim, min_dim)

        # Resize to target size
        image = tf.image.resize(image, self.img_size)

        # Normalize pixel values
        image = tf.clip_by_value(image, 0.0, 255.0)
        image = image / 255.0

        # Convert label to one-hot encoding
        label = tf.one_hot(label, 3)

        return image, label

    def create_dataset(self, split: str = "training") -> tf.data.Dataset:
        """
        Create dataset with enhanced error handling and logging
        """
        split_dir = os.path.join(self.data_dir, split)

        # Initialize containers
        image_files = []
        labels = []
        category_counts = {category: 0 for category in self.categories}

        # Process each category
        for label, category in enumerate(self.categories):
            category_dir = os.path.join(split_dir, category)

            if not os.path.exists(category_dir):
                print(f"Warning: Directory not found: {category_dir}")
                continue

            # Get all valid image files
            valid_files = [
                os.path.join(category_dir, f)
                for f in os.listdir(category_dir)
                if f.lower().endswith((".jpg", ".jpeg", ".png"))
            ]

            category_counts[category] = len(valid_files)
            image_files.extend(valid_files)
            labels.extend([label] * len(valid_files))

        # Print dataset statistics
        print(f"\nDataset statistics for {split}:")
        print("-" * 50)
        for category, count in category_counts.items():
            print(f"{category}: {count} images")
        print(f"Total: {sum(category_counts.values())} images")

        # Verify dataset is not empty
        if not image_files:
            raise ValueError(f"No images found in {split_dir}")

        # Create TensorFlow dataset
        dataset = tf.data.Dataset.from_tensor_slices(
            (tf.constant(image_files), tf.constant(labels, dtype=tf.int32))
        )

        # Configure dataset for performance
        dataset = dataset.map(self._parse_image, num_parallel_calls=tf.data.AUTOTUNE)

        if split == "training":
            # Shuffle training data with larger buffer
            dataset = dataset.shuffle(
                buffer_size=min(50000, len(image_files)), reshuffle_each_iteration=True
            )

        # Optimize performance
        dataset = dataset.batch(self.batch_size).prefetch(tf.data.AUTOTUNE).cache()

        return dataset

    def get_class_weights(self, split: str = "training") -> Dict[int, float]:
        """
        Calculate balanced class weights with improved handling of edge cases
        """
        split_dir = os.path.join(self.data_dir, split)

        # Count images in each class
        counts = {}
        for i, category in enumerate(self.categories):
            category_dir = os.path.join(split_dir, category)
            if os.path.exists(category_dir):
                counts[i] = len(
                    [
                        f
                        for f in os.listdir(category_dir)
                        if f.lower().endswith((".jpg", ".jpeg", ".png"))
                    ]
                )
            else:
                counts[i] = 0
                print(f"Warning: Directory not found: {category_dir}")

        # Calculate total samples
        total_samples = sum(counts.values())
        if total_samples == 0:
            raise ValueError(f"No images found in {split_dir}")

        # Calculate balanced weights
        n_classes = len(self.categories)
        weights = {}
        for class_idx, count in counts.items():
            if count == 0:
                weights[class_idx] = 1.0
            else:
                weights[class_idx] = total_samples / (n_classes * count)

        # Print weight distribution
        print(f"\nClass weights for {split}:")
        for i, category in enumerate(self.categories):
            print(f"{category}: {weights[i]:.4f}")

        return weights

    def validate_dataset(self) -> None:
        """
        Validate dataset integrity and balance
        """
        for split in ["training", "validation", "evaluation"]:
            split_dir = os.path.join(self.data_dir, split)
            if not os.path.exists(split_dir):
                print(f"Warning: Split directory not found: {split_dir}")
                continue

            total_images = 0
            corrupted_images = 0

            for category in self.categories:
                category_dir = os.path.join(split_dir, category)
                if not os.path.exists(category_dir):
                    print(f"Warning: Category directory not found: {category_dir}")
                    continue

                # Check each image
                for img_name in os.listdir(category_dir):
                    if not img_name.lower().endswith((".jpg", ".jpeg", ".png")):
                        continue

                    total_images += 1
                    img_path = os.path.join(category_dir, img_name)

                    try:
                        with tf.io.gfile.GFile(img_path, "rb") as fid:
                            image_data = fid.read()
                            _ = tf.image.decode_jpeg(image_data, channels=3)
                    except tf.errors.InvalidArgumentError:
                        print(f"Corrupted image found: {img_path}")
                        corrupted_images += 1

            print(f"\nDataset validation results for {split}:")
            print(f"Total images: {total_images}")
            print(f"Corrupted images: {corrupted_images}")

================
File: ml/src/model.py
================
import tensorflow as tf
from tensorflow.keras import layers, models


def create_model(input_shape=(224, 224, 3)):
    # Base model (MobileNetV2)
    base_model = tf.keras.applications.MobileNetV2(
        input_shape=input_shape, include_top=False, weights="imagenet"
    )

    # Freeze the base model
    base_model.trainable = False

    # Create new model with 3 output classes
    model = models.Sequential(
        [
            base_model,
            layers.GlobalAveragePooling2D(),
            layers.Dense(128, activation="relu"),
            layers.Dropout(0.2),
            layers.Dense(3, activation="softmax"),  # Changed to 3 outputs with softmax
        ]
    )

    # Compile the model
    model.compile(
        optimizer="adam",
        loss="categorical_crossentropy",  # Use categorical_crossentropy for multi-class
        metrics=["accuracy"],
    )

    return model


def create_model_with_fine_tuning(input_shape=(224, 224, 3), fine_tune_layers=30):
    # Base model (MobileNetV2)
    base_model = tf.keras.applications.MobileNetV2(
        input_shape=input_shape, include_top=False, weights="imagenet"
    )

    # Freeze early layers
    base_model.trainable = True
    for layer in base_model.layers[:-fine_tune_layers]:
        layer.trainable = False

    # Create new model with 3 output classes
    model = models.Sequential(
        [
            base_model,
            layers.GlobalAveragePooling2D(),
            layers.Dense(256, activation="relu"),
            layers.Dropout(0.3),
            layers.Dense(128, activation="relu"),
            layers.Dropout(0.2),
            layers.Dense(3, activation="softmax"),  # Three categories
        ]
    )

    # Compile with a lower learning rate for fine-tuning
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
        loss="categorical_crossentropy",
        metrics=["accuracy"],
    )

    return model


def get_model_summary(model):
    """Get model architecture summary"""
    trainable_params = tf.keras.backend.count_params(
        tf.concat([tf.reshape(w, [-1]) for w in model.trainable_weights], axis=0)
    )
    non_trainable_params = tf.keras.backend.count_params(
        tf.concat([tf.reshape(w, [-1]) for w in model.non_trainable_weights], axis=0)
    )

    print("\nModel Summary:")
    print(f"Total parameters: {trainable_params + non_trainable_params:,}")
    print(f"Trainable parameters: {trainable_params:,}")
    print(f"Non-trainable parameters: {non_trainable_params:,}")

    return {
        "total_params": trainable_params + non_trainable_params,
        "trainable_params": trainable_params,
        "non_trainable_params": non_trainable_params,
    }

================
File: ml/src/organize_dataset.py
================
# organize_dataset.py
import os
import shutil
from pathlib import Path

# Define healthy and unhealthy categories from Food-101 Data Set
HEALTHY_FOODS = [
    "beef_carpaccio",
    "beef_tartare",
    "beet_salad",
    "bibimbap",
    "caesar_salad",
    "caprese_salad",
    "ceviche",
    "chicken_curry",
    "edamame",
    "eggs_benedict",
    "falafel",
    "fried_rice",
    "gnocchi",
    "greek_salad",
    "grilled_salmon",
    "gyoza",
    "huevos_rancheros",
    "lasagna",
    "miso_soup",
    "mussels",
    "omelette",
    "pad_thai",
    "paella",
    "pancakes",
    "pho",
    "ramen",
    "risotto",
    "sashimi",
    "scallops",
    "seaweed_salad",
    "shrimp_and_grits",
    "spring_rolls",
    "steak",
    "sushi",
    "tuna_tartare",
    "waffles",
]

UNHEALTHY_FOODS = [
    "apple_pie",
    "baby_back_ribs",
    "baklava",
    "beignets",
    "bread_pudding",
    "breakfast_burrito",
    "cannoli",
    "carrot_cake",
    "cheesecake",
    "chicken_wings",
    "chocolate_cake",
    "chocolate_mousse",
    "churros",
    "croque_madame",
    "cup_cakes",
    "donuts",
    "french_fries",
    "fried_calamari",
    "hamburger",
    "hot_dog",
    "ice_cream",
    "macaroni_and_cheese",
    "macarons",
    "nachos",
    "onion_rings",
    "pizza",
    "poutine",
    "red_velvet_cake",
]


def create_hybrid_dataset():
    # Define paths and output to our hybrid_dataset (combination of the two)
    food101_path = "../data/food-101/images"
    food5k_path = "../data/Food-5k"
    output_path = "../data/hybrid_dataset"

    # Create directory structure
    for split in ["training", "validation", "evaluation"]:
        os.makedirs(os.path.join(output_path, split, "healthy_food"), exist_ok=True)
        os.makedirs(os.path.join(output_path, split, "non_food"), exist_ok=True)
        os.makedirs(os.path.join(output_path, split, "unhealthy_food"), exist_ok=True)

    # Copy non-food images from Food-5K
    for split in ["training", "validation", "evaluation"]:
        src_dir = os.path.join(food5k_path, split, "non_food")
        dst_dir = os.path.join(output_path, split, "non_food")

        print(f"Copying non-food images from {split} set...")
        for img in os.listdir(src_dir):
            if img.endswith(".jpg"):
                shutil.copy2(os.path.join(src_dir, img), os.path.join(dst_dir, img))

    # Copy and categorize food images from Food-101
    total_images_per_category = 1000  # Adjust this number as needed

    print("\nCopying healthy food images from Food-101...")
    for category in HEALTHY_FOODS:
        category_path = os.path.join(food101_path, category)
        if not os.path.exists(category_path):
            print(f"Warning: Category {category} not found")
            continue

        images = [f for f in os.listdir(category_path) if f.endswith(".jpg")]
        images = images[:total_images_per_category]

        # Calculate split sizes
        num_images = len(images)
        train_size = int(num_images * 0.7)
        val_size = int(num_images * 0.15)

        # Split images
        train_images = images[:train_size]
        val_images = images[train_size : train_size + val_size]
        test_images = images[train_size + val_size :]

        # Copy to respective splits in healthy_food directory
        for split_info in [
            ("training", train_images),
            ("validation", val_images),
            ("evaluation", test_images),
        ]:
            split_name, split_images = split_info
            for img in split_images:
                shutil.copy2(
                    os.path.join(category_path, img),
                    os.path.join(
                        output_path, split_name, "healthy_food", f"{category}_{img}"
                    ),
                )

    print("\nCopying unhealthy food images from Food-101...")
    for category in UNHEALTHY_FOODS:
        # Same process for unhealthy foods
        category_path = os.path.join(food101_path, category)
        if not os.path.exists(category_path):
            print(f"Warning: Category {category} not found")
            continue

        images = [f for f in os.listdir(category_path) if f.endswith(".jpg")]
        images = images[:total_images_per_category]

        num_images = len(images)
        train_size = int(num_images * 0.7)
        val_size = int(num_images * 0.15)

        train_images = images[:train_size]
        val_images = images[train_size : train_size + val_size]
        test_images = images[train_size + val_size :]

        # Copy to respective splits in unhealthy_food directory
        for split_info in [
            ("training", train_images),
            ("validation", val_images),
            ("evaluation", test_images),
        ]:
            split_name, split_images = split_info
            for img in split_images:
                shutil.copy2(
                    os.path.join(category_path, img),
                    os.path.join(
                        output_path, split_name, "unhealthy_food", f"{category}_{img}"
                    ),
                )

    # Print final dataset statistics
    print("\nFinal Dataset Statistics:")
    for split in ["training", "validation", "evaluation"]:
        healthy_count = len(
            os.listdir(os.path.join(output_path, split, "healthy_food"))
        )
        non_food_count = len(os.listdir(os.path.join(output_path, split, "non_food")))
        unhealthy_count = len(
            os.listdir(os.path.join(output_path, split, "unhealthy_food"))
        )
        print(f"\n{split.capitalize()} set:")
        print(f"Healthy food images: {healthy_count}")
        print(f"Non-food images: {non_food_count}")
        print(f"Unhealthy food images: {unhealthy_count}")
        print(f"Total: {healthy_count + non_food_count + unhealthy_count}")


if __name__ == "__main__":
    print("Creating hybrid dataset...")
    create_hybrid_dataset()
    print("\nDone!")

================
File: ml/src/test_api.py
================
# test_api.py
import tensorflow as tf
import numpy as np
from PIL import Image
import os


def load_and_preprocess_image(image_path):
    """Load and preprocess a single image"""
    img = Image.open(image_path)
    img = img.resize((224, 224))
    img_array = np.array(img) / 255.0
    img_array = np.expand_dims(img_array, 0)
    return img_array


def test_images():
    """Test model predictions on test images"""
    # Categories
    CATEGORIES = ["non_food", "food", "junk_food"]

    # Load model
    print("Loading model...")
    model_path = "../model/model_latest.h5"
    try:
        model = tf.keras.models.load_model(model_path)
    except Exception as e:
        print(f"Error loading model: {e}")
        return

    # Test directory
    test_dir = "../test_images"
    test_images = sorted(
        [f for f in os.listdir(test_dir) if f.endswith((".jpg", ".jpeg"))]
    )

    print("\nTesting images...")
    print("=" * 50)

    results = []
    for image_name in test_images:
        image_path = os.path.join(test_dir, image_name)
        try:
            # Process image
            img_array = load_and_preprocess_image(image_path)

            # Get predictions
            predictions = model.predict(img_array, verbose=0)[0]
            predicted_class = np.argmax(predictions)
            confidence = predictions[predicted_class]

            # Store results
            result = {
                "image": image_name,
                "predicted": CATEGORIES[predicted_class],
                "confidence": confidence,
                "probabilities": {
                    cat: float(prob) for cat, prob in zip(CATEGORIES, predictions)
                },
            }
            results.append(result)

            # Print results
            print(f"\nImage: {image_name}")
            print(f"Predicted: {result['predicted']}")
            print(f"Confidence: {confidence:.4f}")
            print("Probabilities:")
            for cat, prob in result["probabilities"].items():
                print(f"  {cat}: {prob:.4f}")
            print("-" * 50)

        except Exception as e:
            print(f"Error processing {image_name}: {e}")

    # Print summary
    print("\nSummary:")
    for category in CATEGORIES:
        count = sum(1 for r in results if r["predicted"] == category)
        print(f"{category}: {count} images")


if __name__ == "__main__":
    test_images()

================
File: ml/src/test_model_webcam.py
================
import tensorflow as tf
import cv2
import numpy as np
import os
import sys


def load_and_preprocess_frame(frame):
    resized = cv2.resize(frame, (224, 224))
    rgb = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)
    normalized = rgb / 255.0
    batched = np.expand_dims(normalized, 0)
    return batched


def main():
    # Load the trained model
    print("Loading model...")
    model_path = "../model_latest.h5"
    if not os.path.exists(model_path):
        print(f"Error: Model not found at {model_path}")
        sys.exit(1)

    model = tf.keras.models.load_model(model_path)

    # Category labels and colors
    CATEGORIES = ["NOT FOOD", "HEALTHY FOOD", "UNHEALTHY FOOD"]
    COLORS = [
        (0, 0, 255),  # Red for NOT FOOD
        (0, 255, 0),  # Green for HEALTHY FOOD
        (0, 165, 255),  # Orange for UNHEALTHY FOOD (BGR format)
    ]

    print("Starting webcam...")
    cap = cv2.VideoCapture(0)

    # Check if camera opened successfully
    if not cap.isOpened():
        print("\nError: Could not open camera")
        print(
            "Please check your camera permissions in System Settings > Privacy & Security > Camera"
        )
        print("Make sure Terminal/Python has permission to access the camera")
        sys.exit(1)

    print("Camera accessed successfully!")
    print("Press 'q' to quit")

    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                print("Failed to grab frame")
                break

            processed_frame = load_and_preprocess_frame(frame)
            predictions = model.predict(processed_frame, verbose=0)[0]
            predicted_class = np.argmax(predictions)
            confidence = predictions[predicted_class]

            # Get all probabilities
            probabilities = {cat: prob for cat, prob in zip(CATEGORIES, predictions)}

            # Prepare text display
            text = CATEGORIES[predicted_class]
            confidence_text = f"Confidence: {confidence:.2f}"

            # Additional probabilities text
            prob_texts = [f"{cat}: {prob:.2f}" for cat, prob in probabilities.items()]

            # Background rectangle for text (make it larger for all probabilities)
            cv2.rectangle(frame, (10, 10), (300, 110), (0, 0, 0), -1)

            # Add main prediction and confidence
            cv2.putText(
                frame,
                text,
                (20, 35),
                cv2.FONT_HERSHEY_SIMPLEX,
                1,
                COLORS[predicted_class],
                2,
            )
            cv2.putText(
                frame,
                confidence_text,
                (20, 60),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.7,
                (255, 255, 255),
                2,
            )

            # Add all probabilities
            y_offset = 85
            cv2.putText(
                frame,
                f"All: {' | '.join(prob_texts)}",
                (20, y_offset),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.4,
                (255, 255, 255),
                1,
            )

            cv2.imshow("Food Detector", frame)

            if cv2.waitKey(1) & 0xFF == ord("q"):
                print("\nQuitting...")
                break

    except KeyboardInterrupt:
        print("\nInterrupted by user")
    except Exception as e:
        print(f"\nAn error occurred: {str(e)}")
    finally:
        cap.release()
        cv2.destroyAllWindows()


if __name__ == "__main__":
    main()

================
File: ml/src/test_model.py
================
# test_model.py
import tensorflow as tf
import numpy as np
from PIL import Image
import os
import random


def load_and_preprocess_image(image_path):
    # Load image
    img = Image.open(image_path)
    # Resize to match model's expected input
    img = img.resize((224, 224))
    # Convert to array and normalize
    img_array = np.array(img) / 255.0
    # Add batch dimension
    img_array = np.expand_dims(img_array, 0)
    return img_array


def test_model():
    # Load the trained model
    print("Loading model...")
    model = tf.keras.models.load_model("../model_final.h5")

    # Print model summary
    print("\nModel Summary:")
    model.summary()

    # Paths for evaluation set
    eval_dir = "../data/hybrid_dataset/evaluation"
    healthy_food_dir = os.path.join(eval_dir, "healthy_food")
    non_food_dir = os.path.join(eval_dir, "non_food")
    unhealthy_food_dir = os.path.join(eval_dir, "unhealthy_food")

    # Get 5 random images from each category
    healthy_food_images = random.sample(
        [f for f in os.listdir(healthy_food_dir) if f.endswith(".jpg")], 5
    )
    non_food_images = random.sample(
        [f for f in os.listdir(non_food_dir) if f.endswith(".jpg")], 5
    )
    unhealthy_food_images = random.sample(
        [f for f in os.listdir(unhealthy_food_dir) if f.endswith(".jpg")], 5
    )

    categories = ["Non-Food", "Healthy Food", "Unhealthy Food"]

    def test_category(images, directory, category_name):
        print(f"\nTesting {category_name} Images:")
        print("=" * 50)
        for img_name in images:
            img_path = os.path.join(directory, img_name)
            img_array = load_and_preprocess_image(img_path)
            predictions = model.predict(img_array, verbose=0)[0]

            predicted_class = np.argmax(predictions)
            confidence = predictions[predicted_class]

            print(f"\nImage: {img_name}")
            print(f"Prediction: {categories[predicted_class]}")
            print(f"Confidence: {confidence:.4f}")
            print("All probabilities:")
            for cat, prob in zip(categories, predictions):
                print(f"  {cat}: {prob:.4f}")
            print("-" * 50)

    # Test all categories
    test_category(healthy_food_images, healthy_food_dir, "Healthy Food")
    test_category(non_food_images, non_food_dir, "Non-Food")
    test_category(unhealthy_food_images, unhealthy_food_dir, "Unhealthy Food")


if __name__ == "__main__":
    print("Testing model on all three categories...")
    test_model()

================
File: ml/src/train.py
================
# train.py
import tensorflow as tf
from tensorflow.keras import layers, models
from dataset import FoodDataset
import os
import shutil


def ensure_directories():
    """Create necessary directories for model saving"""
    # Create both src/checkpoints and checkpoints directories
    directories = ["checkpoints", "src/checkpoints"]
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
        print(f"Created directory: {directory}")


def save_model_with_verification(model, base_path, filename):
    """Save model and verify it exists in both locations"""
    # Save to primary location
    primary_path = os.path.join(base_path, filename)
    model.save(primary_path)
    print(f"Model saved to: {primary_path}")

    # Copy to src/checkpoints for compatibility
    src_path = os.path.join("src/checkpoints", filename)
    shutil.copy2(primary_path, src_path)
    print(f"Model copied to: {src_path}")

    return primary_path, src_path


def train():
    # Configuration
    DATA_DIR = "../data/hybrid_dataset"
    IMG_SIZE = (224, 224)
    BATCH_SIZE = 32
    EPOCHS = 15

    # Ensure directories exist
    ensure_directories()

    print(f"Loading data from: {os.path.abspath(DATA_DIR)}")

    # Create datasets
    dataset = FoodDataset(DATA_DIR, IMG_SIZE, BATCH_SIZE)
    train_ds = dataset.create_dataset("training")
    val_ds = dataset.create_dataset("validation")

    # Get class weights
    class_weights = dataset.get_class_weights("training")
    print("\nClass weights:", class_weights)

    # Create model
    print("\nCreating model...")
    model = models.Sequential(
        [
            tf.keras.applications.MobileNetV2(
                input_shape=(*IMG_SIZE, 3), include_top=False, weights="imagenet"
            ),
            layers.GlobalAveragePooling2D(),
            layers.Dense(256, activation="relu"),
            layers.Dropout(0.4),
            layers.Dense(128, activation="relu"),
            layers.Dropout(0.3),
            layers.Dense(3, activation="softmax"),
        ]
    )

    # Compile model
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
        loss="categorical_crossentropy",
        metrics=["accuracy"],
    )

    # Callbacks
    callbacks = [
        tf.keras.callbacks.ModelCheckpoint(
            filepath="checkpoints/best_model.h5",
            save_best_only=True,
            monitor="val_accuracy",
            mode="max",
            verbose=1,
        ),
        tf.keras.callbacks.EarlyStopping(
            monitor="val_accuracy", patience=5, restore_best_weights=True
        ),
        tf.keras.callbacks.ReduceLROnPlateau(
            monitor="val_loss", factor=0.2, patience=3, min_lr=1e-6
        ),
    ]

    # Train model
    print("\nStarting training...")
    history = model.fit(
        train_ds,
        validation_data=val_ds,
        epochs=EPOCHS,
        callbacks=callbacks,
        class_weight=class_weights,
        verbose=1,
    )

    # Save final model with verification
    print("\nSaving final model...")
    try:
        primary_path, src_path = save_model_with_verification(
            model, "checkpoints", "model.h5"
        )
        print(f"Model successfully saved and verified at:")
        print(f"1. {primary_path}")
        print(f"2. {src_path}")
    except Exception as e:
        print(f"Error saving model: {str(e)}")

    return history, model


if __name__ == "__main__":
    print("Starting training process...")
    try:
        history, model = train()

        # Verify saved model exists
        expected_paths = ["checkpoints/model.h5", "src/checkpoints/model.h5"]
        for path in expected_paths:
            if os.path.exists(path):
                print(f"Verified: Model exists at {path}")
            else:
                print(f"Warning: Model not found at {path}")

    except Exception as e:
        print(f"Error during training: {str(e)}")

================
File: ml/requirements.txt
================
asgiref==3.5.2
certifi==2022.9.24
charset-normalizer==2.1.1
click==8.1.3
confluent-kafka==2.4.0
contourpy==1.0.7
cycler==0.11.0
Django==4.1.3
djangorestframework==3.14.0
Flask==1.1.2
Flask-Login==0.5.0
Flask-SQLAlchemy==2.4.4
fonttools==4.39.4
future==1.0.0
greenlet==2.0.1
idna==3.4
iso8601==2.1.0
itsdangerous==2.1.2
Jinja2==3.1.2
khan-api-wrapper==0.0.18
kiwisolver==1.4.4
MarkupSafe==2.1.1
matplotlib==3.7.1
mpmath==1.2.1
numpy==1.23.5
packaging==23.1
pandas==2.0.2
Pillow==9.3.0
pybraille==1.0.0
pygame==2.1.2
pyparsing==3.0.9
pyserial==3.5
python-dateutil==2.8.2
pytube==12.1.2
pytz==2022.6
PyYAML==6.0.2
rauth==0.7.3
requests==2.28.1
scipy==1.9.3
serial==0.0.97
six==1.16.0
SQLAlchemy==1.4.44
sqlparse==0.4.3
sympy==1.11.1
tzdata==2023.3
urllib3==1.26.12
Werkzeug==2.2.2
tensorflow==2.11.0

================
File: models/user.ts
================
import Joi from "joi";
import mongoose from "mongoose";
import jwt from "jsonwebtoken";

interface IUserDocument extends mongoose.Document {
  firstName: string;
  lastName: string;
  email: string;
  password: string;
  petName: string;
  healthPoints: number;
  mood: "happy" | "sad" | "neutral";
  generateAuthToken(): string;
}

const userSchema = new mongoose.Schema<IUserDocument>({
  firstName: {
    type: String,
    required: true,
    maxlength: 50,
  },
  lastName: {
    type: String,
    required: true,
    maxlength: 50,
  },
  email: {
    type: String,
    required: true,
    minlength: 5,
    maxlength: 255,
    unique: true,
  },
  password: {
    type: String,
    required: true,
    minlength: 5,
    maxlength: 1024,
  },
  petName: {
    type: String,
    required: true,
    minlength: 1,
    maxlength: 255,
  },
  healthPoints: {
    type: Number,
    default: 100,
  },
  mood: {
    type: String,
    enum: ["happy", "sad", "neutral"],
    default: "neutral",
  },
});

userSchema.methods.generateAuthToken = function () {
  const token = jwt.sign(
    {
      _id: this._id,
      firstName: this.firstName,
      lastName: this.lastName,
      role: "user",
    },
    process.env.JWT_PRIVATE_KEY || "this is a secret key"
  );
  return token;
};

export const User = mongoose.model("users", userSchema);

export function validateUser(user) {
  const schema = Joi.object({
    firstName: Joi.string().max(50).required(),
    lastName: Joi.string().max(50).required(),
    email: Joi.string().min(5).max(255).required().email(),
    password: Joi.string().min(5).max(255).required(),
    petName: Joi.string().min(1).max(255).required(),
  });
  return schema.validate(user);
}

================
File: repos/foodRepo.ts
================
import multer, { FileFilterCallback } from "multer";
import path from "path";
import fs from "fs";
import { Request } from "express";
import { fileURLToPath } from "url";

// Types
interface MulterFile {
  fieldname: string;
  originalname: string;
  encoding: string;
  mimetype: string;
  size: number;
  destination: string;
  filename: string;
  path: string;
  buffer: Buffer;
}

// Fix for __dirname in ES modules
const currentFilePath = fileURLToPath(import.meta.url);
const currentDirPath = path.dirname(currentFilePath);

// Create uploads directory path
const uploadPath = path.join(currentDirPath, "..", "ml", "uploads");

// Ensure uploads directory exists
if (!fs.existsSync(uploadPath)) {
  fs.mkdirSync(uploadPath, { recursive: true });
  console.log(`Created uploads directory at: ${uploadPath}`);
}

const storage = multer.diskStorage({
  destination: function (
    _req: Request,
    _file: MulterFile,
    cb: (error: Error | null, destination: string) => void
  ) {
    cb(null, uploadPath);
  },
  filename: function (
    _req: Request,
    file: MulterFile,
    cb: (error: Error | null, filename: string) => void
  ) {
    const uniqueSuffix = Date.now() + "-" + Math.round(Math.random() * 1e9);
    cb(null, uniqueSuffix + "-" + file.originalname);
  },
});

// Add file filter for images
const fileFilter = (
  _req: Request,
  file: MulterFile,
  cb: FileFilterCallback
) => {
  const allowedMimes = ["image/jpeg", "image/png", "image/jpg"];
  if (allowedMimes.includes(file.mimetype)) {
    cb(null, true);
  } else {
    cb(new Error("Invalid file type. Only JPEG and PNG are allowed."));
  }
};

// Create multer instance with configuration
const upload = multer({
  storage,
  fileFilter,
  limits: {
    fileSize: 50 * 1024 * 1024, // 5MB limit
  },
});

export const singleFoodUpload = upload.single("photo");

export async function processFoodFile(file: MulterFile) {
  const result = await fetch("http://localhost:4000/api/ml/classify", {
    method: "POST",
    body: JSON.stringify({
      argument: file.path
    }),
    headers: {
      "Content-Type": "application/json"
    }
  });

  const data = await result.json();

  return {
    data
  };
}

================
File: repos/stateRepo.ts
================
import {User} from "../models/user";

export const getStates = async (req, res) => {
  const userId = process.env.DEMO_USER_ID;
  const user = await User.findById(userId);
  if (!user) return res.status(404).json({error: "User not found."});
  return res.status(200).json({HP: user.healthPoints, mood: user.mood});
};

================
File: repos/userRepo.ts
================
import {User, validateUser} from "../models/user.js";
import Joi from "joi";
import bcrypt from "bcryptjs";
const {hash, genSalt, compare} = bcrypt;
import _ from "lodash";

export const login = async (req, res) => {
  const {error} = validate(req.body);
  if (error) return res.status(400).json({error: error.details[0].message});

  let user = await User.findOne({email: req.body.email});
  if (!user) return res.status(400).json({error: "Invalid email or password."});

  if (!user.password)
    return res.status(400).json({error: "Invalid email or password."});

  const validPassword = await compare(req.body.password, user.password);
  if (!validPassword)
    return res.status(400).json({error: "Invalid email or password."});

  const token = user.generateAuthToken();

  res.status(200).json({
    message: "Login successful",
    token,
    user: {
      _id: user._id,
      email: user.email,
      firstName: user.firstName,
      lastName: user.lastName,
      petName: user.petName,
      healthPoints: user.healthPoints,
      mood: user.mood,
    },
  });
};

export const register = async (req, res) => {
  const {error} = validateUser(req.body);
  if (error) return res.status(400).send(error.details[0].message);

  let user = await User.findOne({email: req.body.email});
  if (user) return res.status(400).send("User already registered.");

  user = new User(
    _.pick(req.body, ["firstName", "lastName", "email", "password", "petName"])
  );
  const salt = await genSalt(10);
  user.password = await hash(user.password, salt);
  await user.save();

  const token = user.generateAuthToken();

  return res.status(201).json({
    message: "Registration successful",
    token,
    user: _.pick(user, [
      "_id",
      "firstName",
      "lastName",
      "email",
      "petName",
      "healthPoints",
      "mood",
    ]),
  });
};

export const getMe = async (req, res) => {
  const user = await User.findById(req.user._id).select("-password");
  return res.status(200).json({
    user: _.pick(user, [
      "_id",
      "firstName",
      "lastName",
      "email",
      "petName",
      "healthPoints",
      "mood",
    ]),
  });
};

function validate(req) {
  const schema = {
    email: Joi.string().min(5).max(255).required().email(),
    password: Joi.string().min(5).max(255).required(),
  };

  return Joi.object(schema).validate(req.body);
}

export const test = (req, res) => {
  return res.status(200).json({message: "Test route"});
};

================
File: routes/auth.ts
================
import {auth} from "./../middleware/auth";
import express from "express";
import {getMe, login, register, test} from "../repos/userRepo";

const router = express.Router();

router.post("/", login);
router.post("/register", register);
router.get("/test", auth, test);
router.get("/me", auth, getMe);

export default router;

================
File: routes/food.ts
================
import { Router, Request, Response } from "express";
import { singleFoodUpload, processFoodFile } from "../repos/foodRepo.js";

const router = Router();

// POST /food
router.post("/", singleFoodUpload, (req: Request, res: Response) => {
  try {
    console.log("Received request with file:", req.file);

    if (!req.file) {
      console.log("No file in request");
      return res.status(400).json({ error: "No file uploaded." });
    }

    // Process the uploaded file
    console.log("Processing file...");
    console.log("File size:", req.file.size);
    console.log("File path:", req.file);
    const processedFile = processFoodFile(req.file);
    console.log("Processed file result:", processedFile);

    return res.json(processedFile);
  } catch (error) {
    console.error("Error in /food route:", error);
    return res.status(500).json({
      error: "Internal server error.",
      details: error instanceof Error ? error.message : "Unknown error",
    });
  }
});

export default router;

================
File: routes/ml.ts
================
// import express, { Request, Response } from "express";
import { spawn } from "child_process";
import path from "path";
// import multer from "multer";
// import { fileURLToPath } from "url";
// import fs from "fs/promises";

// // Types
// interface ClassificationResult {
//   category: string;
//   confidence: number;
//   all_probabilities: {
//     [key: string]: number;
//   };
// }

// interface ErrorResponse {
//   error: string;
//   details?: unknown;
// }

// // Configuration
// const __filename = fileURLToPath(import.meta.url);
// const __dirname = path.dirname(__filename);

// // Multer configuration with file filtering and size limits
// const storage = multer.diskStorage({
//   destination: "uploads/",
//   filename: (req, file, cb) => {
//     const uniqueSuffix = `${Date.now()}-${Math.round(Math.random() * 1e9)}`;
//     cb(null, `${uniqueSuffix}-${file.originalname}`);
//   },
// });

// const fileFilter = (
//   req: Express.Request,
//   file: Express.Multer.File,
//   cb: multer.FileFilterCallback
// ) => {
//   const allowedTypes = ["image/jpeg", "image/png", "image/jpg"];

//   if (allowedTypes.includes(file.mimetype)) {
//     cb(null, true);
//   } else {
//     cb(new Error("Invalid file type. Only JPEG and PNG are allowed."));
//   }
// };

// const upload = multer({
//   storage,
//   fileFilter,
//   limits: {
//     fileSize: 5 * 1024 * 1024, // 5MB limit
//   },
// });

// const router = express.Router();

// // Helper function to run Python script
// const runPythonScript = async (
//   scriptPath: string,
//   args: string[] = []
// ): Promise<string> => {
//   return new Promise((resolve, reject) => {
//     const pythonProcess = spawn("python", [scriptPath, ...args]);
//     let result = "";
//     let errorOutput = "";

//     pythonProcess.stdout.on("data", (data) => {
//       result += data.toString();
//     });

//     pythonProcess.stderr.on("data", (data) => {
//       errorOutput += data.toString();
//     });

//     pythonProcess.on("close", (code) => {
//       if (code === 0) {
//         resolve(result);
//       } else {
//         reject(
//           new Error(`Python script failed with code ${code}: ${errorOutput}`)
//         );
//       }
//     });

//     pythonProcess.on("error", (error) => {
//       reject(error);
//     });
//   });
// };

// // Cleanup function for uploaded files
// const cleanupFile = async (filePath: string): Promise<void> => {
//   try {
//     await fs.unlink(filePath);
//   } catch (error) {
//     console.error(`Failed to cleanup file ${filePath}:`, error);
//   }
// };

// // Routes
// router.post(
//   "/predict",
//   upload.single("image"),
//   async (
//     req: Request,
//     res: Response<ClassificationResult | ErrorResponse>
//   ): Promise<void> => {
//     if (!req.file) {
//       res.status(400).json({ error: "No image provided" });
//       return;
//     }

//     try {
//       const result = await runPythonScript(
//         path.join(__dirname, "../ml/src/api.py"),
//         [req.file.path]
//       );

//       const classification: ClassificationResult = JSON.parse(result);
//       res.json(classification);
//     } catch (error) {
//       console.error("Classification error:", error);
//       res.status(500).json({
//         error: "Classification failed",
//         details: error instanceof Error ? error.message : String(error),
//       });
//     } finally {
//       // Cleanup uploaded file
//       if (req.file) {
//         await cleanupFile(req.file.path);
//       }
//     }
//   }
// );

// router.get(
//   "/training-info",
//   async (req: Request, res: Response): Promise<void> => {
//     try {
//       const result = await runPythonScript(
//         path.join(__dirname, "../ml/src/test_api.py")
//       );

//       const info = JSON.parse(result);
//       res.json(info);
//     } catch (error) {
//       console.error("Training info error:", error);
//       res.status(500).json({
//         error: "Could not get training info",
//         details: error instanceof Error ? error.message : String(error),
//       });
//     }
//   }
// );

// // Error handling middleware
// router.use(
//   (error: Error, req: Request, res: Response, next: express.NextFunction) => {
//     console.error("ML Router Error:", error);

//     if (error instanceof multer.MulterError) {
//       if (error.code === "LIMIT_FILE_SIZE") {
//         res
//           .status(400)
//           .json({ error: "File size is too large. Maximum size is 5MB." });
//       } else {
//         res.status(400).json({ error: error.message });
//       }
//     } else {
//       res.status(500).json({ error: "Internal server error" });
//     }
//   }
// );

// export default router;


// ... existing code ...

import { Router, Request, Response } from "express";

const router = Router();

const __dirname = path.resolve();

// Routes
router.post("/classify", async (req: Request, res: Response): Promise<void> => {
  const { argument } = req.body;
  
  if (!argument) {
    res.status(400).json({ error: "No argument provided" });
    return;
  }

  try {
    console.log("Running Python script with argument:", argument);
    const result = await new Promise<string>((resolve, reject) => {
      const pythonProcess = spawn("python3", [`${__dirname}/ml/src/test_api.py`, argument]);
      let result = "";
      let errorOutput = "";

      pythonProcess.stdout.on("data", (data) => {
        result += data.toString();
      });

      pythonProcess.stderr.on("data", (data) => {
        errorOutput += data.toString();
      });

      pythonProcess.on("close", (code) => {
        if (code === 0) {
          resolve(result);
        } else {
          reject(new Error(`Python script failed with code ${code}: ${errorOutput}`));
        }
      });

      pythonProcess.on("error", (error) => {
        reject(error);
      });
    });

    const classification = JSON.parse(result);
    res.json(classification);
  } catch (error) {
    console.error("Script execution error:", error);
    res.status(500).json({
      error: "Script execution failed",
      details: error instanceof Error ? error.message : String(error),
    });
  }
});

export default router;
// ... existing code ...

================
File: routes/pet.ts
================
// backend/routes/pet.ts
import express, { Request, Response } from "express";
import { analyzePetInteraction } from "../services/llmService";
import { User } from "../models/user";

const router = express.Router();

const DEMO_USER_ID = process.env.DEMO_USER_ID;

const getDemoUser = async () => {
  let user = await User.findById(DEMO_USER_ID);
  if (!user) {
    // Create demo user if none exists
    user = await User.create({
      _id: DEMO_USER_ID, // Use the specific ID
      firstName: "Demo",
      lastName: "User",
      email: "demo@example.com",
      password: "demo123", // In a real app, this should be hashed
      petName: "Kitty",
      healthPoints: 100,
      mood: "neutral",
    });
  }
  return user;
};

router.post("/interact", (req: Request, res: Response) => {
  (async () => {
    try {
      const { speech } = req.body;
      if (!speech) {
        return res.status(400).json({ error: "Speech content is required" });
      }

      // Analyze speech with LLM
      const analysis = await analyzePetInteraction(speech);

      // Get demo user
      const user = await getDemoUser();

      // Calculate new health points
      const newHP = Math.max(
        0,
        Math.min(100, user.healthPoints + analysis.moodImpact)
      );

      // Determine new mood based on health points
      let newMood: "happy" | "sad" | "neutral";
      if (newHP >= 70) {
        newMood = "happy";
      } else if (newHP <= 30) {
        newMood = "sad";
      } else {
        newMood = "neutral";
      }

      // Update user's pet state
      await User.findByIdAndUpdate(user._id, {
        healthPoints: newHP,
        mood: newMood,
      });

      // Return response
      return res.json({
        petState: {
          healthPoints: newHP,
          mood: newMood,
          petName: user.petName,
        },
        analysis,
      });
    } catch (error) {
      return res.status(500).json({
        error: "Failed to process pet interaction",
        details: error instanceof Error ? error.message : String(error),
      });
    }
  })();
});

router.get("/state", (req: Request, res: Response) => {
  (async () => {
    try {
      const user = await getDemoUser();

      return res.json({
        petName: user.petName,
        healthPoints: user.healthPoints,
        mood: user.mood,
      });
    } catch (error) {
      return res.status(500).json({
        error: "Failed to get pet state",
        details: error instanceof Error ? error.message : String(error),
      });
    }
  })();
});

export default router;

================
File: routes/state.ts
================
import {auth} from "./../middleware/auth";
import express from "express";
import {login, register, test} from "../repos/userRepo";
import { getStates } from "../repos/stateRepo";

const router = express.Router();

router.get("/", getStates);

export default router;

================
File: services/llmService.ts
================
// backend/services/llmService.ts
import OpenAI from "openai";
import dotenv from "dotenv";
dotenv.config();

if (!process.env.DEEPSEEK_API_KEY) {
  throw new Error("DEEPSEEK_API_KEY is not set in environment variables");
}

const openai = new OpenAI({
  apiKey: process.env.DEEPSEEK_API_KEY,
  baseURL: "https://api.deepseek.com",
});

interface PetAnalysis {
  moodImpact: number;
  sentiment: "positive" | "negative" | "neutral";
  catReaction: string;
}

export async function analyzePetInteraction(
  speech: string
): Promise<PetAnalysis> {
  try {
    console.log(" Processing speech:", speech);

    const response = await openai.chat.completions.create({
      model: "deepseek-chat",
      messages: [
        {
          role: "system",
          content: `You are an emotion analyzer for a virtual pet cat. Analyze the speech and return ONLY a JSON object.
          
For example:
For positive speech: {"moodImpact": 7, "sentiment": "positive", "catReaction": "Purrs loudly and rubs against your leg"}
For negative speech: {"moodImpact": -5, "sentiment": "negative", "catReaction": "Flattens ears and backs away"}
For neutral speech: {"moodImpact": 0, "sentiment": "neutral", "catReaction": "Glances briefly and continues current activity"}

Rules:
1. Positive speech (praise, love) = positive impact (1 to 10)
2. Negative speech (scolding, threats) = negative impact (-1 to -10)
3. Stronger emotions = stronger impact
4. Cat reactions must be realistic

Return only the JSON object, no additional text or formatting.`,
        },
        { role: "user", content: speech },
      ],
      temperature: 0.7,
      max_tokens: 150,
    });

    console.log(" Raw LLM Response:", response.choices[0].message.content);

    const content = response.choices[0].message.content;
    if (!content) {
      throw new Error("Empty response from LLM");
    }

    // Clean up the response if needed
    const cleanContent = content
      .replace(/```json\n?/, "")
      .replace(/```\n?/, "")
      .trim();

    try {
      const analysis = JSON.parse(cleanContent);

      // Validate the response
      if (
        typeof analysis.moodImpact !== "number" ||
        !["positive", "negative", "neutral"].includes(analysis.sentiment) ||
        typeof analysis.catReaction !== "string"
      ) {
        throw new Error("Invalid response format from LLM");
      }

      return analysis;
    } catch (parseError) {
      console.error("Parse error:", parseError);
      console.error("Content that failed to parse:", cleanContent);
      throw new Error("Failed to parse LLM response");
    }
  } catch (error) {
    console.error(" LLM Analysis failed:", error);
    // Return a fallback response instead of throwing
    return {
      moodImpact: 0,
      sentiment: "neutral",
      catReaction: "The cat seems unsure how to react.",
    };
  }
}

================
File: startup/db.ts
================
import mongoose from "mongoose";

const uri = process.env.MONGO_URI;

if (!uri) {
  console.error("MONGODB_URI is not defined.");
  process.exit(1);
}

export async function connectToMongo() {
  try {
    await mongoose.connect(uri || "");
    console.log("Connected to MongoDB using Mongoose");
  } catch (err) {
    console.error("Error connecting to MongoDB with Mongoose:", err);
  }
}

================
File: startup/routes.ts
================
import authRoutes from "../routes/auth.js";
import stateRoutes from "../routes/state.js";
import petRoutes from "../routes/pet.js";
import foodRoutes from "../routes/food.js";
import mlRoutes from "../routes/ml.js";
const setupRoutes = (app) => {
  app.use("/api/auth", authRoutes);
  app.use("/api/state", stateRoutes);
  app.use("/api/pet", petRoutes);
  app.use("/api/food", foodRoutes);
  app.use("/api/ml", mlRoutes);
};

export default setupRoutes;

================
File: tests/llm-pet-test.js
================
// backend/tests/llm-pet-test.js
import fetch from "node-fetch";

const positiveSpeeches = [
  {
    description: "Loving and affectionate",
    speech:
      "You're the most precious kitty in the world! I love you so much and I'll always take care of you. You make me so happy every single day!",
  },
  {
    description: "Praising good behavior",
    speech:
      "What a good kitty you are! You're so well-behaved and gentle. I'm so proud of how you always use your scratching post!",
  },
  {
    description: "Gentle and soothing",
    speech:
      "Hey sweet baby, you're such a calm and beautiful cat. Your purring makes me feel so peaceful and loved.",
  },
];

const negativeSpeeches = [
  {
    description: "Harsh scolding",
    speech:
      "You're such a terrible cat! I can't believe you knocked everything off the table again! I regret getting you!",
  },
  {
    description: "Threatening",
    speech:
      "If you don't stop scratching the furniture, I'm going to get rid of you! You're the worst pet ever!",
  },
  {
    description: "Cold and dismissive",
    speech:
      "Just go away, I don't want you around. You're nothing but trouble and I wish I never got a cat.",
  },
];

async function testPetInteractions() {
  const baseUrl = "http://localhost:4000/api/pet";

  try {
    // Initial state
    console.log("\n Getting initial state...");
    const stateRes = await fetch(`${baseUrl}/state`);
    const initialState = await stateRes.json();
    console.log("Initial state:", initialState);

    // Test positive interactions
    console.log("\n Testing Positive Interactions ");
    for (const test of positiveSpeeches) {
      console.log(`\n Testing: ${test.description}`);
      const res = await fetch(`${baseUrl}/interact`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ speech: test.speech }),
      });
      const result = await res.json();
      console.log("Response:", result);
      console.log("Mood Impact:", result.analysis.moodImpact);
      console.log("Cat's Reaction:", result.analysis.catReaction);

      // Wait between tests
      await new Promise((resolve) => setTimeout(resolve, 1000));
    }

    // Get intermediate state
    console.log("\n Checking state after positive interactions...");
    const midStateRes = await fetch(`${baseUrl}/state`);
    const midState = await midStateRes.json();
    console.log("Current state:", midState);

    // Test negative interactions
    console.log("\n Testing Negative Interactions ");
    for (const test of negativeSpeeches) {
      console.log(`\n Testing: ${test.description}`);
      const res = await fetch(`${baseUrl}/interact`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ speech: test.speech }),
      });
      const result = await res.json();
      console.log("Response:", result);
      console.log("Mood Impact:", result.analysis.moodImpact);
      console.log("Cat's Reaction:", result.analysis.catReaction);

      // Wait between tests
      await new Promise((resolve) => setTimeout(resolve, 1000));
    }

    // Get final state
    console.log("\n Getting final state...");
    const finalStateRes = await fetch(`${baseUrl}/state`);
    const finalState = await finalStateRes.json();
    console.log("Final state:", finalState);

    // Print summary
    console.log("\n Test Summary");
    console.log("Initial Health Points:", initialState.healthPoints);
    console.log("Final Health Points:", finalState.healthPoints);
    console.log(
      "Total Mood Change:",
      finalState.healthPoints - initialState.healthPoints
    );
  } catch (error) {
    console.error(" Test failed:", error);
    if (error.response) {
      console.error("Response status:", error.response.status);
      console.error("Response data:", await error.response.text());
    }
  }
}

console.log(" Starting Cat Interaction Tests ");
testPetInteractions().then(() => {
  console.log("\n Tests completed");
});

================
File: tests/llm-test.ts
================
// backend/tests/llm-test.ts
import dotenv from "dotenv";
dotenv.config();

import { analyzePetInteraction } from "../services/llmService.js";

async function testLLM() {
  console.log(" Testing LLM Service...");
  console.log("API Key present:", !!process.env.DEEPSEEK_API_KEY);

  const tests = [
    {
      type: "Positive",
      speech:
        "You're such a good kitty! I love you so much! You're the best cat ever!",
    },
    {
      type: "Negative",
      speech: "Bad cat! Get out of here! I don't want you around anymore!",
    },
    {
      type: "Neutral",
      speech: "Hey cat, what are you doing over there?",
    },
  ];

  for (const test of tests) {
    console.log(`\n Testing ${test.type} Speech:`);
    console.log("Input:", test.speech);

    try {
      const result = await analyzePetInteraction(test.speech);
      console.log(" Analysis Result:");
      console.log("Mood Impact:", result.moodImpact);
      console.log("Sentiment:", result.sentiment);
      console.log("Cat Reaction:", result.catReaction);
    } catch (error) {
      console.error(" Test Failed:", error);
      if (error instanceof Error) {
        console.error("Error Details:", error.message);
        console.error("Stack:", error.stack);
      }
    }
  }
}

console.log(" Starting LLM Tests");
testLLM()
  .then(() => console.log("\n Tests Completed"))
  .catch((error) => console.error(" Test Suite Failed:", error));

================
File: .gitignore
================
# Create a comprehensive .gitignore in project root
cat > .gitignore << 'EOL'
# Dependencies
/node_modules
**/node_modules

# Python
**/__pycache__
*.py[cod]
*.$py.class

# Virtual Environment - Specific paths
/backend/ml/venv
/backend/ml/venv/
/backend/ml/venv/*
**/venv
**/.venv

# Build artifacts
/dist
/build
*.egg-info

# Environment files
.env
.env.local
.env.*

# IDE
.vscode
.idea
*.swp
*.swo

# OS
.DS_Store
Thumbs.db

# Project specific
/backend/uploads

# Debug logs
npm-debug.log*
yarn-debug.log*
yarn-error.log*
EOL

================
File: index.ts
================
import dotenv from "dotenv";
dotenv.config();

import {connectToMongo} from "./startup/db.js";
import express from "express";
import setupRoutes from "./startup/routes.js";
import cors from "cors";

console.log(process.env.MONGO_URI);
console.log(process.env.FRONTEND_URL);
console.log(process.env.PORT);

const app = express();
const port = process.env.PORT || 4000;

// Enable CORS for frontend
app.use(
  cors({
    origin: process.env.FRONTEND_URL,
  })
);

// Connect to MongoDB
// connectToMongo();
app.use(express.json());

// Setup Routes
setupRoutes(app);

// Default Route
app.get("/", (req, res) => {
  res.send(`Hello, World!`);
});

// Start the Server
app.listen(port, () => {
  connectToMongo();
  console.log(`Server is running on http://localhost:${port}`);
});

================
File: package.json
================
{
  "name": "backend",
  "version": "1.0.0",
  "main": "index.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1",
    "dev": "nodemon --watch . --ext ts --exec 'tsx --require dotenv/config index.ts'",
    "test:llm": "tsx tests/llm-test.ts"
  },
  "author": "",
  "license": "ISC",
  "description": "",
  "type": "module",
  "dependencies": {
    "@paralleldrive/cuid2": "^2.2.2",
    "bcryptjs": "^2.4.3",
    "cloudinary": "^2.5.1",
    "cookie-parser": "^1.4.7",
    "cors": "^2.8.5",
    "dotenv": "^16.4.7",
    "express": "^4.21.0",
    "express-session": "^1.18.1",
    "joi": "^17.13.3",
    "jsonwebtoken": "^9.0.2",
    "lodash": "^4.17.21",
    "mongodb": "^6.9.0",
    "multer": "^1.4.5-lts.1",
    "openai": "^4.85.1"
  },
  "devDependencies": {
    "@types/express": "^5.0.0",
    "@types/jsonwebtoken": "^9.0.7",
    "@types/multer": "^1.4.7",
    "@types/lodash": "^4.17.13",
    "@types/mongoose": "^5.11.97",
    "@types/node": "^22.10.1",
    "node-fetch": "^3.3.2",
    "nodemon": "^3.1.9",
    "ts-node": "^10.9.2",
    "tsx": "^4.19.2",
    "typescript": "^5.7.3"
  }
}
