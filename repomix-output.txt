This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-02-16T08:02:25.824Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

================================================================
Directory Structure
================================================================
app/
  app/
    (tabs)/
      _layout.tsx
      explore.tsx
      index.tsx
    _layout.tsx
    +not-found.tsx
  components/
    __tests__/
      __snapshots__/
        ThemedText-test.tsx.snap
      ThemedText-test.tsx
    ui/
      IconSymbol.ios.tsx
      IconSymbol.tsx
      TabBarBackground.ios.tsx
      TabBarBackground.tsx
    Collapsible.tsx
    ExternalLink.tsx
    HapticTab.tsx
    HelloWave.tsx
    ParallaxScrollView.tsx
    ThemedText.tsx
    ThemedView.tsx
  constants/
    Colors.ts
  hooks/
    useColorScheme.ts
    useColorScheme.web.ts
    useThemeColor.ts
  scripts/
    reset-project.js
  .gitignore
  app.json
  package.json
  README.md
  tsconfig.json
backend/
  middleware/
    auth.ts
  ml/
    src/
      api.py
      dataset.py
      model.py
      organize_dataset.py
      test_api.py
      test_model_webcam.py
      test_model.py
      train.py
    requirements.txt
  models/
    user.ts
  repos/
    foodRepo.ts
    stateRepo.ts
    userRepo.ts
  routes/
    auth.ts
    food.ts
    ml.ts
    state.ts
  startup/
    db.ts
    routes.ts
  .gitignore
  index.ts
  package.json
.gitignore
package.json
README.md
setup.sh

================================================================
Files
================================================================

================
File: app/app/(tabs)/_layout.tsx
================
import { Tabs } from 'expo-router';
import React from 'react';
import { Platform } from 'react-native';

import { HapticTab } from '@/components/HapticTab';
import { IconSymbol } from '@/components/ui/IconSymbol';
import TabBarBackground from '@/components/ui/TabBarBackground';
import { Colors } from '@/constants/Colors';
import { useColorScheme } from '@/hooks/useColorScheme';

export default function TabLayout() {
  const colorScheme = useColorScheme();

  return (
    <Tabs
      screenOptions={{
        tabBarActiveTintColor: Colors[colorScheme ?? 'light'].tint,
        headerShown: false,
        tabBarButton: HapticTab,
        tabBarBackground: TabBarBackground,
        tabBarStyle: Platform.select({
          ios: {
            // Use a transparent background on iOS to show the blur effect
            position: 'absolute',
          },
          default: {},
        }),
      }}>
      <Tabs.Screen
        name="index"
        options={{
          title: 'Home',
          tabBarIcon: ({ color }) => <IconSymbol size={28} name="house.fill" color={color} />,
        }}
      />
      <Tabs.Screen
        name="explore"
        options={{
          title: 'Explore',
          tabBarIcon: ({ color }) => <IconSymbol size={28} name="paperplane.fill" color={color} />,
        }}
      />
    </Tabs>
  );
}

================
File: app/app/(tabs)/explore.tsx
================
import { StyleSheet, Image, Platform } from 'react-native';

import { Collapsible } from '@/components/Collapsible';
import { ExternalLink } from '@/components/ExternalLink';
import ParallaxScrollView from '@/components/ParallaxScrollView';
import { ThemedText } from '@/components/ThemedText';
import { ThemedView } from '@/components/ThemedView';
import { IconSymbol } from '@/components/ui/IconSymbol';

export default function TabTwoScreen() {
  return (
    <ParallaxScrollView
      headerBackgroundColor={{ light: '#D0D0D0', dark: '#353636' }}
      headerImage={
        <IconSymbol
          size={310}
          color="#808080"
          name="chevron.left.forwardslash.chevron.right"
          style={styles.headerImage}
        />
      }>
      <ThemedView style={styles.titleContainer}>
        <ThemedText type="title">Explore</ThemedText>
      </ThemedView>
      <ThemedText>This app includes example code to help you get started.</ThemedText>
      <Collapsible title="File-based routing">
        <ThemedText>
          This app has two screens:{' '}
          <ThemedText type="defaultSemiBold">app/(tabs)/index.tsx</ThemedText> and{' '}
          <ThemedText type="defaultSemiBold">app/(tabs)/explore.tsx</ThemedText>
        </ThemedText>
        <ThemedText>
          The layout file in <ThemedText type="defaultSemiBold">app/(tabs)/_layout.tsx</ThemedText>{' '}
          sets up the tab navigator.
        </ThemedText>
        <ExternalLink href="https://docs.expo.dev/router/introduction">
          <ThemedText type="link">Learn more</ThemedText>
        </ExternalLink>
      </Collapsible>
      <Collapsible title="Android, iOS, and web support">
        <ThemedText>
          You can open this project on Android, iOS, and the web. To open the web version, press{' '}
          <ThemedText type="defaultSemiBold">w</ThemedText> in the terminal running this project.
        </ThemedText>
      </Collapsible>
      <Collapsible title="Images">
        <ThemedText>
          For static images, you can use the <ThemedText type="defaultSemiBold">@2x</ThemedText> and{' '}
          <ThemedText type="defaultSemiBold">@3x</ThemedText> suffixes to provide files for
          different screen densities
        </ThemedText>
        <Image source={require('@/assets/images/react-logo.png')} style={{ alignSelf: 'center' }} />
        <ExternalLink href="https://reactnative.dev/docs/images">
          <ThemedText type="link">Learn more</ThemedText>
        </ExternalLink>
      </Collapsible>
      <Collapsible title="Custom fonts">
        <ThemedText>
          Open <ThemedText type="defaultSemiBold">app/_layout.tsx</ThemedText> to see how to load{' '}
          <ThemedText style={{ fontFamily: 'SpaceMono' }}>
            custom fonts such as this one.
          </ThemedText>
        </ThemedText>
        <ExternalLink href="https://docs.expo.dev/versions/latest/sdk/font">
          <ThemedText type="link">Learn more</ThemedText>
        </ExternalLink>
      </Collapsible>
      <Collapsible title="Light and dark mode components">
        <ThemedText>
          This template has light and dark mode support. The{' '}
          <ThemedText type="defaultSemiBold">useColorScheme()</ThemedText> hook lets you inspect
          what the user's current color scheme is, and so you can adjust UI colors accordingly.
        </ThemedText>
        <ExternalLink href="https://docs.expo.dev/develop/user-interface/color-themes/">
          <ThemedText type="link">Learn more</ThemedText>
        </ExternalLink>
      </Collapsible>
      <Collapsible title="Animations">
        <ThemedText>
          This template includes an example of an animated component. The{' '}
          <ThemedText type="defaultSemiBold">components/HelloWave.tsx</ThemedText> component uses
          the powerful <ThemedText type="defaultSemiBold">react-native-reanimated</ThemedText>{' '}
          library to create a waving hand animation.
        </ThemedText>
        {Platform.select({
          ios: (
            <ThemedText>
              The <ThemedText type="defaultSemiBold">components/ParallaxScrollView.tsx</ThemedText>{' '}
              component provides a parallax effect for the header image.
            </ThemedText>
          ),
        })}
      </Collapsible>
    </ParallaxScrollView>
  );
}

const styles = StyleSheet.create({
  headerImage: {
    color: '#808080',
    bottom: -90,
    left: -35,
    position: 'absolute',
  },
  titleContainer: {
    flexDirection: 'row',
    gap: 8,
  },
});

================
File: app/app/(tabs)/index.tsx
================
import { Image, StyleSheet, Platform } from 'react-native';

import { HelloWave } from '@/components/HelloWave';
import ParallaxScrollView from '@/components/ParallaxScrollView';
import { ThemedText } from '@/components/ThemedText';
import { ThemedView } from '@/components/ThemedView';

export default function HomeScreen() {
  return (
    <ParallaxScrollView
      headerBackgroundColor={{ light: '#A1CEDC', dark: '#1D3D47' }}
      headerImage={
        <Image
          source={require('@/assets/images/partial-react-logo.png')}
          style={styles.reactLogo}
        />
      }>
      <ThemedView style={styles.titleContainer}>
        <ThemedText type="title">Welcome!</ThemedText>
        <HelloWave />
      </ThemedView>
      <ThemedView style={styles.stepContainer}>
        <ThemedText type="subtitle">Step 1: Try it</ThemedText>
        <ThemedText>
          Edit <ThemedText type="defaultSemiBold">app/(tabs)/index.tsx</ThemedText> to see changes.
          Press{' '}
          <ThemedText type="defaultSemiBold">
            {Platform.select({
              ios: 'cmd + d',
              android: 'cmd + m',
              web: 'F12'
            })}
          </ThemedText>{' '}
          to open developer tools.
        </ThemedText>
      </ThemedView>
      <ThemedView style={styles.stepContainer}>
        <ThemedText type="subtitle">Step 2: Explore</ThemedText>
        <ThemedText>
          Tap the Explore tab to learn more about what's included in this starter app.
        </ThemedText>
      </ThemedView>
      <ThemedView style={styles.stepContainer}>
        <ThemedText type="subtitle">Step 3: Get a fresh start</ThemedText>
        <ThemedText>
          When you're ready, run{' '}
          <ThemedText type="defaultSemiBold">npm run reset-project</ThemedText> to get a fresh{' '}
          <ThemedText type="defaultSemiBold">app</ThemedText> directory. This will move the current{' '}
          <ThemedText type="defaultSemiBold">app</ThemedText> to{' '}
          <ThemedText type="defaultSemiBold">app-example</ThemedText>.
        </ThemedText>
      </ThemedView>
    </ParallaxScrollView>
  );
}

const styles = StyleSheet.create({
  titleContainer: {
    flexDirection: 'row',
    alignItems: 'center',
    gap: 8,
  },
  stepContainer: {
    gap: 8,
    marginBottom: 8,
  },
  reactLogo: {
    height: 178,
    width: 290,
    bottom: 0,
    left: 0,
    position: 'absolute',
  },
});

================
File: app/app/_layout.tsx
================
import { DarkTheme, DefaultTheme, ThemeProvider } from '@react-navigation/native';
import { useFonts } from 'expo-font';
import { Stack } from 'expo-router';
import * as SplashScreen from 'expo-splash-screen';
import { StatusBar } from 'expo-status-bar';
import { useEffect } from 'react';
import 'react-native-reanimated';

import { useColorScheme } from '@/hooks/useColorScheme';

// Prevent the splash screen from auto-hiding before asset loading is complete.
SplashScreen.preventAutoHideAsync();

export default function RootLayout() {
  const colorScheme = useColorScheme();
  const [loaded] = useFonts({
    SpaceMono: require('../assets/fonts/SpaceMono-Regular.ttf'),
  });

  useEffect(() => {
    if (loaded) {
      SplashScreen.hideAsync();
    }
  }, [loaded]);

  if (!loaded) {
    return null;
  }

  return (
    <ThemeProvider value={colorScheme === 'dark' ? DarkTheme : DefaultTheme}>
      <Stack>
        <Stack.Screen name="(tabs)" options={{ headerShown: false }} />
        <Stack.Screen name="+not-found" />
      </Stack>
      <StatusBar style="auto" />
    </ThemeProvider>
  );
}

================
File: app/app/+not-found.tsx
================
import { Link, Stack } from 'expo-router';
import { StyleSheet } from 'react-native';

import { ThemedText } from '@/components/ThemedText';
import { ThemedView } from '@/components/ThemedView';

export default function NotFoundScreen() {
  return (
    <>
      <Stack.Screen options={{ title: 'Oops!' }} />
      <ThemedView style={styles.container}>
        <ThemedText type="title">This screen doesn't exist.</ThemedText>
        <Link href="/" style={styles.link}>
          <ThemedText type="link">Go to home screen!</ThemedText>
        </Link>
      </ThemedView>
    </>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    alignItems: 'center',
    justifyContent: 'center',
    padding: 20,
  },
  link: {
    marginTop: 15,
    paddingVertical: 15,
  },
});

================
File: app/components/__tests__/__snapshots__/ThemedText-test.tsx.snap
================
// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`renders correctly 1`] = `
<Text
  style={
    [
      {
        "color": "#11181C",
      },
      {
        "fontSize": 16,
        "lineHeight": 24,
      },
      undefined,
      undefined,
      undefined,
      undefined,
      undefined,
    ]
  }
>
  Snapshot test!
</Text>
`;

================
File: app/components/__tests__/ThemedText-test.tsx
================
import * as React from 'react';
import renderer from 'react-test-renderer';

import { ThemedText } from '../ThemedText';

it(`renders correctly`, () => {
  const tree = renderer.create(<ThemedText>Snapshot test!</ThemedText>).toJSON();

  expect(tree).toMatchSnapshot();
});

================
File: app/components/ui/IconSymbol.ios.tsx
================
import { SymbolView, SymbolViewProps, SymbolWeight } from 'expo-symbols';
import { StyleProp, ViewStyle } from 'react-native';

export function IconSymbol({
  name,
  size = 24,
  color,
  style,
  weight = 'regular',
}: {
  name: SymbolViewProps['name'];
  size?: number;
  color: string;
  style?: StyleProp<ViewStyle>;
  weight?: SymbolWeight;
}) {
  return (
    <SymbolView
      weight={weight}
      tintColor={color}
      resizeMode="scaleAspectFit"
      name={name}
      style={[
        {
          width: size,
          height: size,
        },
        style,
      ]}
    />
  );
}

================
File: app/components/ui/IconSymbol.tsx
================
// This file is a fallback for using MaterialIcons on Android and web.

import MaterialIcons from '@expo/vector-icons/MaterialIcons';
import { SymbolWeight } from 'expo-symbols';
import React from 'react';
import { OpaqueColorValue, StyleProp, ViewStyle } from 'react-native';

// Add your SFSymbol to MaterialIcons mappings here.
const MAPPING = {
  // See MaterialIcons here: https://icons.expo.fyi
  // See SF Symbols in the SF Symbols app on Mac.
  'house.fill': 'home',
  'paperplane.fill': 'send',
  'chevron.left.forwardslash.chevron.right': 'code',
  'chevron.right': 'chevron-right',
} as Partial<
  Record<
    import('expo-symbols').SymbolViewProps['name'],
    React.ComponentProps<typeof MaterialIcons>['name']
  >
>;

export type IconSymbolName = keyof typeof MAPPING;

/**
 * An icon component that uses native SFSymbols on iOS, and MaterialIcons on Android and web. This ensures a consistent look across platforms, and optimal resource usage.
 *
 * Icon `name`s are based on SFSymbols and require manual mapping to MaterialIcons.
 */
export function IconSymbol({
  name,
  size = 24,
  color,
  style,
}: {
  name: IconSymbolName;
  size?: number;
  color: string | OpaqueColorValue;
  style?: StyleProp<ViewStyle>;
  weight?: SymbolWeight;
}) {
  return <MaterialIcons color={color} size={size} name={MAPPING[name]} style={style} />;
}

================
File: app/components/ui/TabBarBackground.ios.tsx
================
import { useBottomTabBarHeight } from '@react-navigation/bottom-tabs';
import { BlurView } from 'expo-blur';
import { StyleSheet } from 'react-native';
import { useSafeAreaInsets } from 'react-native-safe-area-context';

export default function BlurTabBarBackground() {
  return (
    <BlurView
      // System chrome material automatically adapts to the system's theme
      // and matches the native tab bar appearance on iOS.
      tint="systemChromeMaterial"
      intensity={100}
      style={StyleSheet.absoluteFill}
    />
  );
}

export function useBottomTabOverflow() {
  const tabHeight = useBottomTabBarHeight();
  const { bottom } = useSafeAreaInsets();
  return tabHeight - bottom;
}

================
File: app/components/ui/TabBarBackground.tsx
================
// This is a shim for web and Android where the tab bar is generally opaque.
export default undefined;

export function useBottomTabOverflow() {
  return 0;
}

================
File: app/components/Collapsible.tsx
================
import { PropsWithChildren, useState } from 'react';
import { StyleSheet, TouchableOpacity } from 'react-native';

import { ThemedText } from '@/components/ThemedText';
import { ThemedView } from '@/components/ThemedView';
import { IconSymbol } from '@/components/ui/IconSymbol';
import { Colors } from '@/constants/Colors';
import { useColorScheme } from '@/hooks/useColorScheme';

export function Collapsible({ children, title }: PropsWithChildren & { title: string }) {
  const [isOpen, setIsOpen] = useState(false);
  const theme = useColorScheme() ?? 'light';

  return (
    <ThemedView>
      <TouchableOpacity
        style={styles.heading}
        onPress={() => setIsOpen((value) => !value)}
        activeOpacity={0.8}>
        <IconSymbol
          name="chevron.right"
          size={18}
          weight="medium"
          color={theme === 'light' ? Colors.light.icon : Colors.dark.icon}
          style={{ transform: [{ rotate: isOpen ? '90deg' : '0deg' }] }}
        />

        <ThemedText type="defaultSemiBold">{title}</ThemedText>
      </TouchableOpacity>
      {isOpen && <ThemedView style={styles.content}>{children}</ThemedView>}
    </ThemedView>
  );
}

const styles = StyleSheet.create({
  heading: {
    flexDirection: 'row',
    alignItems: 'center',
    gap: 6,
  },
  content: {
    marginTop: 6,
    marginLeft: 24,
  },
});

================
File: app/components/ExternalLink.tsx
================
import { Link } from 'expo-router';
import { openBrowserAsync } from 'expo-web-browser';
import { type ComponentProps } from 'react';
import { Platform } from 'react-native';

type Props = Omit<ComponentProps<typeof Link>, 'href'> & { href: string };

export function ExternalLink({ href, ...rest }: Props) {
  return (
    <Link
      target="_blank"
      {...rest}
      href={href}
      onPress={async (event) => {
        if (Platform.OS !== 'web') {
          // Prevent the default behavior of linking to the default browser on native.
          event.preventDefault();
          // Open the link in an in-app browser.
          await openBrowserAsync(href);
        }
      }}
    />
  );
}

================
File: app/components/HapticTab.tsx
================
import { BottomTabBarButtonProps } from '@react-navigation/bottom-tabs';
import { PlatformPressable } from '@react-navigation/elements';
import * as Haptics from 'expo-haptics';

export function HapticTab(props: BottomTabBarButtonProps) {
  return (
    <PlatformPressable
      {...props}
      onPressIn={(ev) => {
        if (process.env.EXPO_OS === 'ios') {
          // Add a soft haptic feedback when pressing down on the tabs.
          Haptics.impactAsync(Haptics.ImpactFeedbackStyle.Light);
        }
        props.onPressIn?.(ev);
      }}
    />
  );
}

================
File: app/components/HelloWave.tsx
================
import { useEffect } from 'react';
import { StyleSheet } from 'react-native';
import Animated, {
  useSharedValue,
  useAnimatedStyle,
  withTiming,
  withRepeat,
  withSequence,
} from 'react-native-reanimated';

import { ThemedText } from '@/components/ThemedText';

export function HelloWave() {
  const rotationAnimation = useSharedValue(0);

  useEffect(() => {
    rotationAnimation.value = withRepeat(
      withSequence(withTiming(25, { duration: 150 }), withTiming(0, { duration: 150 })),
      4 // Run the animation 4 times
    );
  }, []);

  const animatedStyle = useAnimatedStyle(() => ({
    transform: [{ rotate: `${rotationAnimation.value}deg` }],
  }));

  return (
    <Animated.View style={animatedStyle}>
      <ThemedText style={styles.text}>ðŸ‘‹</ThemedText>
    </Animated.View>
  );
}

const styles = StyleSheet.create({
  text: {
    fontSize: 28,
    lineHeight: 32,
    marginTop: -6,
  },
});

================
File: app/components/ParallaxScrollView.tsx
================
import type { PropsWithChildren, ReactElement } from 'react';
import { StyleSheet } from 'react-native';
import Animated, {
  interpolate,
  useAnimatedRef,
  useAnimatedStyle,
  useScrollViewOffset,
} from 'react-native-reanimated';

import { ThemedView } from '@/components/ThemedView';
import { useBottomTabOverflow } from '@/components/ui/TabBarBackground';
import { useColorScheme } from '@/hooks/useColorScheme';

const HEADER_HEIGHT = 250;

type Props = PropsWithChildren<{
  headerImage: ReactElement;
  headerBackgroundColor: { dark: string; light: string };
}>;

export default function ParallaxScrollView({
  children,
  headerImage,
  headerBackgroundColor,
}: Props) {
  const colorScheme = useColorScheme() ?? 'light';
  const scrollRef = useAnimatedRef<Animated.ScrollView>();
  const scrollOffset = useScrollViewOffset(scrollRef);
  const bottom = useBottomTabOverflow();
  const headerAnimatedStyle = useAnimatedStyle(() => {
    return {
      transform: [
        {
          translateY: interpolate(
            scrollOffset.value,
            [-HEADER_HEIGHT, 0, HEADER_HEIGHT],
            [-HEADER_HEIGHT / 2, 0, HEADER_HEIGHT * 0.75]
          ),
        },
        {
          scale: interpolate(scrollOffset.value, [-HEADER_HEIGHT, 0, HEADER_HEIGHT], [2, 1, 1]),
        },
      ],
    };
  });

  return (
    <ThemedView style={styles.container}>
      <Animated.ScrollView
        ref={scrollRef}
        scrollEventThrottle={16}
        scrollIndicatorInsets={{ bottom }}
        contentContainerStyle={{ paddingBottom: bottom }}>
        <Animated.View
          style={[
            styles.header,
            { backgroundColor: headerBackgroundColor[colorScheme] },
            headerAnimatedStyle,
          ]}>
          {headerImage}
        </Animated.View>
        <ThemedView style={styles.content}>{children}</ThemedView>
      </Animated.ScrollView>
    </ThemedView>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
  },
  header: {
    height: HEADER_HEIGHT,
    overflow: 'hidden',
  },
  content: {
    flex: 1,
    padding: 32,
    gap: 16,
    overflow: 'hidden',
  },
});

================
File: app/components/ThemedText.tsx
================
import { Text, type TextProps, StyleSheet } from 'react-native';

import { useThemeColor } from '@/hooks/useThemeColor';

export type ThemedTextProps = TextProps & {
  lightColor?: string;
  darkColor?: string;
  type?: 'default' | 'title' | 'defaultSemiBold' | 'subtitle' | 'link';
};

export function ThemedText({
  style,
  lightColor,
  darkColor,
  type = 'default',
  ...rest
}: ThemedTextProps) {
  const color = useThemeColor({ light: lightColor, dark: darkColor }, 'text');

  return (
    <Text
      style={[
        { color },
        type === 'default' ? styles.default : undefined,
        type === 'title' ? styles.title : undefined,
        type === 'defaultSemiBold' ? styles.defaultSemiBold : undefined,
        type === 'subtitle' ? styles.subtitle : undefined,
        type === 'link' ? styles.link : undefined,
        style,
      ]}
      {...rest}
    />
  );
}

const styles = StyleSheet.create({
  default: {
    fontSize: 16,
    lineHeight: 24,
  },
  defaultSemiBold: {
    fontSize: 16,
    lineHeight: 24,
    fontWeight: '600',
  },
  title: {
    fontSize: 32,
    fontWeight: 'bold',
    lineHeight: 32,
  },
  subtitle: {
    fontSize: 20,
    fontWeight: 'bold',
  },
  link: {
    lineHeight: 30,
    fontSize: 16,
    color: '#0a7ea4',
  },
});

================
File: app/components/ThemedView.tsx
================
import { View, type ViewProps } from 'react-native';

import { useThemeColor } from '@/hooks/useThemeColor';

export type ThemedViewProps = ViewProps & {
  lightColor?: string;
  darkColor?: string;
};

export function ThemedView({ style, lightColor, darkColor, ...otherProps }: ThemedViewProps) {
  const backgroundColor = useThemeColor({ light: lightColor, dark: darkColor }, 'background');

  return <View style={[{ backgroundColor }, style]} {...otherProps} />;
}

================
File: app/constants/Colors.ts
================
/**
 * Below are the colors that are used in the app. The colors are defined in the light and dark mode.
 * There are many other ways to style your app. For example, [Nativewind](https://www.nativewind.dev/), [Tamagui](https://tamagui.dev/), [unistyles](https://reactnativeunistyles.vercel.app), etc.
 */

const tintColorLight = '#0a7ea4';
const tintColorDark = '#fff';

export const Colors = {
  light: {
    text: '#11181C',
    background: '#fff',
    tint: tintColorLight,
    icon: '#687076',
    tabIconDefault: '#687076',
    tabIconSelected: tintColorLight,
  },
  dark: {
    text: '#ECEDEE',
    background: '#151718',
    tint: tintColorDark,
    icon: '#9BA1A6',
    tabIconDefault: '#9BA1A6',
    tabIconSelected: tintColorDark,
  },
};

================
File: app/hooks/useColorScheme.ts
================
export { useColorScheme } from 'react-native';

================
File: app/hooks/useColorScheme.web.ts
================
import { useEffect, useState } from 'react';
import { useColorScheme as useRNColorScheme } from 'react-native';

/**
 * To support static rendering, this value needs to be re-calculated on the client side for web
 */
export function useColorScheme() {
  const [hasHydrated, setHasHydrated] = useState(false);

  useEffect(() => {
    setHasHydrated(true);
  }, []);

  const colorScheme = useRNColorScheme();

  if (hasHydrated) {
    return colorScheme;
  }

  return 'light';
}

================
File: app/hooks/useThemeColor.ts
================
/**
 * Learn more about light and dark modes:
 * https://docs.expo.dev/guides/color-schemes/
 */

import { Colors } from '@/constants/Colors';
import { useColorScheme } from '@/hooks/useColorScheme';

export function useThemeColor(
  props: { light?: string; dark?: string },
  colorName: keyof typeof Colors.light & keyof typeof Colors.dark
) {
  const theme = useColorScheme() ?? 'light';
  const colorFromProps = props[theme];

  if (colorFromProps) {
    return colorFromProps;
  } else {
    return Colors[theme][colorName];
  }
}

================
File: app/scripts/reset-project.js
================
#!/usr/bin/env node

/**
 * This script is used to reset the project to a blank state.
 * It deletes or moves the /app, /components, /hooks, /scripts, and /constants directories to /app-example based on user input and creates a new /app directory with an index.tsx and _layout.tsx file.
 * You can remove the `reset-project` script from package.json and safely delete this file after running it.
 */

const fs = require("fs");
const path = require("path");
const readline = require("readline");

const root = process.cwd();
const oldDirs = ["app", "components", "hooks", "constants", "scripts"];
const exampleDir = "app-example";
const newAppDir = "app";
const exampleDirPath = path.join(root, exampleDir);

const indexContent = `import { Text, View } from "react-native";

export default function Index() {
  return (
    <View
      style={{
        flex: 1,
        justifyContent: "center",
        alignItems: "center",
      }}
    >
      <Text>Edit app/index.tsx to edit this screen.</Text>
    </View>
  );
}
`;

const layoutContent = `import { Stack } from "expo-router";

export default function RootLayout() {
  return <Stack />;
}
`;

const rl = readline.createInterface({
  input: process.stdin,
  output: process.stdout,
});

const moveDirectories = async (userInput) => {
  try {
    if (userInput === "y") {
      // Create the app-example directory
      await fs.promises.mkdir(exampleDirPath, { recursive: true });
      console.log(`ðŸ“ /${exampleDir} directory created.`);
    }

    // Move old directories to new app-example directory or delete them
    for (const dir of oldDirs) {
      const oldDirPath = path.join(root, dir);
      if (fs.existsSync(oldDirPath)) {
        if (userInput === "y") {
          const newDirPath = path.join(root, exampleDir, dir);
          await fs.promises.rename(oldDirPath, newDirPath);
          console.log(`âž¡ï¸ /${dir} moved to /${exampleDir}/${dir}.`);
        } else {
          await fs.promises.rm(oldDirPath, { recursive: true, force: true });
          console.log(`âŒ /${dir} deleted.`);
        }
      } else {
        console.log(`âž¡ï¸ /${dir} does not exist, skipping.`);
      }
    }

    // Create new /app directory
    const newAppDirPath = path.join(root, newAppDir);
    await fs.promises.mkdir(newAppDirPath, { recursive: true });
    console.log("\nðŸ“ New /app directory created.");

    // Create index.tsx
    const indexPath = path.join(newAppDirPath, "index.tsx");
    await fs.promises.writeFile(indexPath, indexContent);
    console.log("ðŸ“„ app/index.tsx created.");

    // Create _layout.tsx
    const layoutPath = path.join(newAppDirPath, "_layout.tsx");
    await fs.promises.writeFile(layoutPath, layoutContent);
    console.log("ðŸ“„ app/_layout.tsx created.");

    console.log("\nâœ… Project reset complete. Next steps:");
    console.log(
      `1. Run \`npx expo start\` to start a development server.\n2. Edit app/index.tsx to edit the main screen.${
        userInput === "y"
          ? `\n3. Delete the /${exampleDir} directory when you're done referencing it.`
          : ""
      }`
    );
  } catch (error) {
    console.error(`âŒ Error during script execution: ${error.message}`);
  }
};

rl.question(
  "Do you want to move existing files to /app-example instead of deleting them? (Y/n): ",
  (answer) => {
    const userInput = answer.trim().toLowerCase() || "y";
    if (userInput === "y" || userInput === "n") {
      moveDirectories(userInput).finally(() => rl.close());
    } else {
      console.log("âŒ Invalid input. Please enter 'Y' or 'N'.");
      rl.close();
    }
  }
);

================
File: app/.gitignore
================
# Learn more https://docs.github.com/en/get-started/getting-started-with-git/ignoring-files

# dependencies
node_modules/

# Expo
.expo/
dist/
web-build/
expo-env.d.ts

# Native
*.orig.*
*.jks
*.p8
*.p12
*.key
*.mobileprovision

# Metro
.metro-health-check*

# debug
npm-debug.*
yarn-debug.*
yarn-error.*

# macOS
.DS_Store
*.pem

# local env files
.env*.local

# typescript
*.tsbuildinfo

app-example

================
File: app/app.json
================
{
  "expo": {
    "name": "app",
    "slug": "app",
    "version": "1.0.0",
    "orientation": "portrait",
    "icon": "./assets/images/icon.png",
    "scheme": "myapp",
    "userInterfaceStyle": "automatic",
    "newArchEnabled": true,
    "ios": {
      "supportsTablet": true
    },
    "android": {
      "adaptiveIcon": {
        "foregroundImage": "./assets/images/adaptive-icon.png",
        "backgroundColor": "#ffffff"
      }
    },
    "web": {
      "bundler": "metro",
      "output": "static",
      "favicon": "./assets/images/favicon.png"
    },
    "plugins": [
      "expo-router",
      [
        "expo-splash-screen",
        {
          "image": "./assets/images/splash-icon.png",
          "imageWidth": 200,
          "resizeMode": "contain",
          "backgroundColor": "#ffffff"
        }
      ]
    ],
    "experiments": {
      "typedRoutes": true
    }
  }
}

================
File: app/package.json
================
{
  "name": "app",
  "main": "expo-router/entry",
  "version": "1.0.0",
  "scripts": {
    "start": "expo start",
    "reset-project": "node ./scripts/reset-project.js",
    "android": "expo start --android",
    "ios": "expo start --ios",
    "web": "expo start --web",
    "test": "jest --watchAll",
    "lint": "expo lint"
  },
  "jest": {
    "preset": "jest-expo"
  },
  "dependencies": {
    "@expo/vector-icons": "^14.0.2",
    "@react-navigation/bottom-tabs": "^7.2.0",
    "@react-navigation/native": "^7.0.14",
    "expo": "~52.0.35",
    "expo-blur": "~14.0.3",
    "expo-constants": "~17.0.6",
    "expo-font": "~13.0.3",
    "expo-haptics": "~14.0.1",
    "expo-linking": "~7.0.5",
    "expo-router": "~4.0.17",
    "expo-splash-screen": "~0.29.22",
    "expo-status-bar": "~2.0.1",
    "expo-symbols": "~0.2.2",
    "expo-system-ui": "~4.0.8",
    "expo-web-browser": "~14.0.2",
    "react": "18.3.1",
    "react-dom": "18.3.1",
    "react-native": "0.76.7",
    "react-native-gesture-handler": "~2.20.2",
    "react-native-reanimated": "~3.16.1",
    "react-native-safe-area-context": "4.12.0",
    "react-native-screens": "~4.4.0",
    "react-native-web": "~0.19.13",
    "react-native-webview": "13.12.5"
  },
  "devDependencies": {
    "@babel/core": "^7.25.2",
    "@types/jest": "^29.5.12",
    "@types/react": "~18.3.12",
    "@types/react-test-renderer": "^18.3.0",
    "jest": "^29.2.1",
    "jest-expo": "~52.0.4",
    "react-test-renderer": "18.3.1",
    "typescript": "^5.3.3"
  },
  "private": true
}

================
File: app/README.md
================
# Welcome to your Expo app ðŸ‘‹

This is an [Expo](https://expo.dev) project created with [`create-expo-app`](https://www.npmjs.com/package/create-expo-app).

## Get started

1. Install dependencies

   ```bash
   npm install
   ```

2. Start the app

   ```bash
    npx expo start
   ```

In the output, you'll find options to open the app in a

- [development build](https://docs.expo.dev/develop/development-builds/introduction/)
- [Android emulator](https://docs.expo.dev/workflow/android-studio-emulator/)
- [iOS simulator](https://docs.expo.dev/workflow/ios-simulator/)
- [Expo Go](https://expo.dev/go), a limited sandbox for trying out app development with Expo

You can start developing by editing the files inside the **app** directory. This project uses [file-based routing](https://docs.expo.dev/router/introduction).

## Get a fresh project

When you're ready, run:

```bash
npm run reset-project
```

This command will move the starter code to the **app-example** directory and create a blank **app** directory where you can start developing.

## Learn more

To learn more about developing your project with Expo, look at the following resources:

- [Expo documentation](https://docs.expo.dev/): Learn fundamentals, or go into advanced topics with our [guides](https://docs.expo.dev/guides).
- [Learn Expo tutorial](https://docs.expo.dev/tutorial/introduction/): Follow a step-by-step tutorial where you'll create a project that runs on Android, iOS, and the web.

## Join the community

Join our community of developers creating universal apps.

- [Expo on GitHub](https://github.com/expo/expo): View our open source platform and contribute.
- [Discord community](https://chat.expo.dev): Chat with Expo users and ask questions.

================
File: app/tsconfig.json
================
{
  "extends": "expo/tsconfig.base",
  "compilerOptions": {
    "target": "ES2020",
    "module": "ESNext",
    "moduleResolution": "node",
    "esModuleInterop": true,
    "strict": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "outDir": "./dist",
    "rootDir": "./",
    "types": ["node"],
    "resolveJsonModule": true,
    "paths": {
      "@/*": [
        "./*"
      ]
    }
  },
  "include": [
    "**/*.ts",
    "**/*.tsx",
    ".expo/types/**/*.ts",
    "expo-env.d.ts"
  ],
  "exclude": ["node_modules"]
}

================
File: backend/middleware/auth.ts
================
import jwt from "jsonwebtoken";

export const auth = (req, res, next) => {
  // Try to get token from cookies first (for web clients)
  let token = req.cookies?.jwt_token;

  // If not found, check Authorization header (for React Native)
  if (!token && req.headers.authorization) {
    const authHeader = req.headers.authorization;
    if (authHeader.startsWith("Bearer ")) {
      token = authHeader.split(" ")[1]; // Extract token from Bearer scheme
    }
  }

  if (!token) {
    return res.status(401).json({error: "Access denied. No token provided."});
  }

  const jwtPrivateKey = process.env.JWT_PRIVATE_KEY;
  if (!jwtPrivateKey) {
    return res.status(500).json({error: "JWT private key is not defined."});
  }

  try {
    const decoded = jwt.verify(token, jwtPrivateKey);
    req.user = decoded;
    next();
  } catch (ex) {
    res.status(400).json({error: "Invalid token."});
  }
};

================
File: backend/ml/src/api.py
================
import sys
import json
import tensorflow as tf
import numpy as np
from PIL import Image

# Define categories
CATEGORIES = ["non_food", "food", "junk_food"]


def load_model():
    # Load the model from the relative path
    model_path = "../model/model_latest.h5"
    try:
        return tf.keras.models.load_model(model_path)
    except Exception as e:
        print(json.dumps({"error": f"Failed to load model: {str(e)}"}))
        sys.exit(1)


def preprocess_image(image_path):
    try:
        # Open and preprocess the image
        image = Image.open(image_path)
        image = image.resize((224, 224))
        image = np.array(image) / 255.0
        image = np.expand_dims(image, axis=0)
        return image
    except Exception as e:
        print(json.dumps({"error": f"Failed to process image: {str(e)}"}))
        sys.exit(1)


def main():
    if len(sys.argv) != 2:
        print(json.dumps({"error": "Image path not provided"}))
        sys.exit(1)

    image_path = sys.argv[1]

    # Load model
    model = load_model()

    # Process image
    processed_image = preprocess_image(image_path)

    try:
        # Make prediction
        predictions = model.predict(processed_image)[0]
        predicted_class = np.argmax(predictions)
        confidence = float(predictions[predicted_class])

        # Prepare response
        result = {
            "category": CATEGORIES[predicted_class],
            "confidence": confidence,
            "all_probabilities": {
                cat: float(prob) for cat, prob in zip(CATEGORIES, predictions)
            },
        }

        # Print result as JSON string
        print(json.dumps(result))

    except Exception as e:
        print(json.dumps({"error": f"Prediction failed: {str(e)}"}))
        sys.exit(1)


if __name__ == "__main__":
    main()

================
File: backend/ml/src/dataset.py
================
# dataset.py
import tensorflow as tf
import os
import numpy as np
from typing import Tuple, Dict


class FoodDataset:
    def __init__(
        self,
        data_dir: str,
        img_size: Tuple[int, int] = (224, 224),
        batch_size: int = 32,
    ):
        """
        Initialize FoodDataset with enhanced preprocessing and validation

        Args:
            data_dir: Root directory of the dataset
            img_size: Target size for images (height, width)
            batch_size: Batch size for training
        """
        self.data_dir = data_dir
        self.img_size = img_size
        self.batch_size = batch_size
        self.categories = ["non_food", "healthy_food", "unhealthy_food"]

    def _parse_image(
        self, filename: tf.Tensor, label: tf.Tensor
    ) -> Tuple[tf.Tensor, tf.Tensor]:
        """
        Enhanced image parsing with robust augmentation and preprocessing
        """
        # Convert filename to string
        filename = tf.cast(filename, tf.string)
        label = tf.cast(label, tf.int32)

        # Read and decode image
        image = tf.io.read_file(filename)
        image = tf.image.decode_jpeg(image, channels=3)

        # Enhanced data augmentation pipeline
        image = tf.cast(image, tf.float32)

        # Random augmentations for training diversity
        image = tf.image.random_brightness(image, 0.2)
        image = tf.image.random_contrast(image, 0.8, 1.2)
        image = tf.image.random_saturation(image, 0.8, 1.2)
        image = tf.image.random_hue(image, 0.1)
        image = tf.image.random_flip_left_right(image)

        # 50% chance of additional augmentations
        if tf.random.uniform([]) > 0.5:
            image = tf.image.transpose(image)
            image = tf.image.random_flip_up_down(image)

        # Center crop before resize for consistent aspect ratio
        shape = tf.shape(image)
        min_dim = tf.minimum(shape[0], shape[1])
        image = tf.image.resize_with_crop_or_pad(image, min_dim, min_dim)

        # Resize to target size
        image = tf.image.resize(image, self.img_size)

        # Normalize pixel values
        image = tf.clip_by_value(image, 0.0, 255.0)
        image = image / 255.0

        # Convert label to one-hot encoding
        label = tf.one_hot(label, 3)

        return image, label

    def create_dataset(self, split: str = "training") -> tf.data.Dataset:
        """
        Create dataset with enhanced error handling and logging
        """
        split_dir = os.path.join(self.data_dir, split)

        # Initialize containers
        image_files = []
        labels = []
        category_counts = {category: 0 for category in self.categories}

        # Process each category
        for label, category in enumerate(self.categories):
            category_dir = os.path.join(split_dir, category)

            if not os.path.exists(category_dir):
                print(f"Warning: Directory not found: {category_dir}")
                continue

            # Get all valid image files
            valid_files = [
                os.path.join(category_dir, f)
                for f in os.listdir(category_dir)
                if f.lower().endswith((".jpg", ".jpeg", ".png"))
            ]

            category_counts[category] = len(valid_files)
            image_files.extend(valid_files)
            labels.extend([label] * len(valid_files))

        # Print dataset statistics
        print(f"\nDataset statistics for {split}:")
        print("-" * 50)
        for category, count in category_counts.items():
            print(f"{category}: {count} images")
        print(f"Total: {sum(category_counts.values())} images")

        # Verify dataset is not empty
        if not image_files:
            raise ValueError(f"No images found in {split_dir}")

        # Create TensorFlow dataset
        dataset = tf.data.Dataset.from_tensor_slices(
            (tf.constant(image_files), tf.constant(labels, dtype=tf.int32))
        )

        # Configure dataset for performance
        dataset = dataset.map(self._parse_image, num_parallel_calls=tf.data.AUTOTUNE)

        if split == "training":
            # Shuffle training data with larger buffer
            dataset = dataset.shuffle(
                buffer_size=min(50000, len(image_files)), reshuffle_each_iteration=True
            )

        # Optimize performance
        dataset = dataset.batch(self.batch_size).prefetch(tf.data.AUTOTUNE).cache()

        return dataset

    def get_class_weights(self, split: str = "training") -> Dict[int, float]:
        """
        Calculate balanced class weights with improved handling of edge cases
        """
        split_dir = os.path.join(self.data_dir, split)

        # Count images in each class
        counts = {}
        for i, category in enumerate(self.categories):
            category_dir = os.path.join(split_dir, category)
            if os.path.exists(category_dir):
                counts[i] = len(
                    [
                        f
                        for f in os.listdir(category_dir)
                        if f.lower().endswith((".jpg", ".jpeg", ".png"))
                    ]
                )
            else:
                counts[i] = 0
                print(f"Warning: Directory not found: {category_dir}")

        # Calculate total samples
        total_samples = sum(counts.values())
        if total_samples == 0:
            raise ValueError(f"No images found in {split_dir}")

        # Calculate balanced weights
        n_classes = len(self.categories)
        weights = {}
        for class_idx, count in counts.items():
            if count == 0:
                weights[class_idx] = 1.0
            else:
                weights[class_idx] = total_samples / (n_classes * count)

        # Print weight distribution
        print(f"\nClass weights for {split}:")
        for i, category in enumerate(self.categories):
            print(f"{category}: {weights[i]:.4f}")

        return weights

    def validate_dataset(self) -> None:
        """
        Validate dataset integrity and balance
        """
        for split in ["training", "validation", "evaluation"]:
            split_dir = os.path.join(self.data_dir, split)
            if not os.path.exists(split_dir):
                print(f"Warning: Split directory not found: {split_dir}")
                continue

            total_images = 0
            corrupted_images = 0

            for category in self.categories:
                category_dir = os.path.join(split_dir, category)
                if not os.path.exists(category_dir):
                    print(f"Warning: Category directory not found: {category_dir}")
                    continue

                # Check each image
                for img_name in os.listdir(category_dir):
                    if not img_name.lower().endswith((".jpg", ".jpeg", ".png")):
                        continue

                    total_images += 1
                    img_path = os.path.join(category_dir, img_name)

                    try:
                        with tf.io.gfile.GFile(img_path, "rb") as fid:
                            image_data = fid.read()
                            _ = tf.image.decode_jpeg(image_data, channels=3)
                    except tf.errors.InvalidArgumentError:
                        print(f"Corrupted image found: {img_path}")
                        corrupted_images += 1

            print(f"\nDataset validation results for {split}:")
            print(f"Total images: {total_images}")
            print(f"Corrupted images: {corrupted_images}")

================
File: backend/ml/src/model.py
================
import tensorflow as tf
from tensorflow.keras import layers, models


def create_model(input_shape=(224, 224, 3)):
    # Base model (MobileNetV2)
    base_model = tf.keras.applications.MobileNetV2(
        input_shape=input_shape, include_top=False, weights="imagenet"
    )

    # Freeze the base model
    base_model.trainable = False

    # Create new model with 3 output classes
    model = models.Sequential(
        [
            base_model,
            layers.GlobalAveragePooling2D(),
            layers.Dense(128, activation="relu"),
            layers.Dropout(0.2),
            layers.Dense(3, activation="softmax"),  # Changed to 3 outputs with softmax
        ]
    )

    # Compile the model
    model.compile(
        optimizer="adam",
        loss="categorical_crossentropy",  # Use categorical_crossentropy for multi-class
        metrics=["accuracy"],
    )

    return model


def create_model_with_fine_tuning(input_shape=(224, 224, 3), fine_tune_layers=30):
    # Base model (MobileNetV2)
    base_model = tf.keras.applications.MobileNetV2(
        input_shape=input_shape, include_top=False, weights="imagenet"
    )

    # Freeze early layers
    base_model.trainable = True
    for layer in base_model.layers[:-fine_tune_layers]:
        layer.trainable = False

    # Create new model with 3 output classes
    model = models.Sequential(
        [
            base_model,
            layers.GlobalAveragePooling2D(),
            layers.Dense(256, activation="relu"),
            layers.Dropout(0.3),
            layers.Dense(128, activation="relu"),
            layers.Dropout(0.2),
            layers.Dense(3, activation="softmax"),  # Three categories
        ]
    )

    # Compile with a lower learning rate for fine-tuning
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
        loss="categorical_crossentropy",
        metrics=["accuracy"],
    )

    return model


def get_model_summary(model):
    """Get model architecture summary"""
    trainable_params = tf.keras.backend.count_params(
        tf.concat([tf.reshape(w, [-1]) for w in model.trainable_weights], axis=0)
    )
    non_trainable_params = tf.keras.backend.count_params(
        tf.concat([tf.reshape(w, [-1]) for w in model.non_trainable_weights], axis=0)
    )

    print("\nModel Summary:")
    print(f"Total parameters: {trainable_params + non_trainable_params:,}")
    print(f"Trainable parameters: {trainable_params:,}")
    print(f"Non-trainable parameters: {non_trainable_params:,}")

    return {
        "total_params": trainable_params + non_trainable_params,
        "trainable_params": trainable_params,
        "non_trainable_params": non_trainable_params,
    }

================
File: backend/ml/src/organize_dataset.py
================
# organize_dataset.py
import os
import shutil
from pathlib import Path

# Define healthy and unhealthy categories from Food-101 Data Set
HEALTHY_FOODS = [
    "beef_carpaccio",
    "beef_tartare",
    "beet_salad",
    "bibimbap",
    "caesar_salad",
    "caprese_salad",
    "ceviche",
    "chicken_curry",
    "edamame",
    "eggs_benedict",
    "falafel",
    "fried_rice",
    "gnocchi",
    "greek_salad",
    "grilled_salmon",
    "gyoza",
    "huevos_rancheros",
    "lasagna",
    "miso_soup",
    "mussels",
    "omelette",
    "pad_thai",
    "paella",
    "pancakes",
    "pho",
    "ramen",
    "risotto",
    "sashimi",
    "scallops",
    "seaweed_salad",
    "shrimp_and_grits",
    "spring_rolls",
    "steak",
    "sushi",
    "tuna_tartare",
    "waffles",
]

UNHEALTHY_FOODS = [
    "apple_pie",
    "baby_back_ribs",
    "baklava",
    "beignets",
    "bread_pudding",
    "breakfast_burrito",
    "cannoli",
    "carrot_cake",
    "cheesecake",
    "chicken_wings",
    "chocolate_cake",
    "chocolate_mousse",
    "churros",
    "croque_madame",
    "cup_cakes",
    "donuts",
    "french_fries",
    "fried_calamari",
    "hamburger",
    "hot_dog",
    "ice_cream",
    "macaroni_and_cheese",
    "macarons",
    "nachos",
    "onion_rings",
    "pizza",
    "poutine",
    "red_velvet_cake",
]


def create_hybrid_dataset():
    # Define paths and output to our hybrid_dataset (combination of the two)
    food101_path = "../data/food-101/images"
    food5k_path = "../data/Food-5k"
    output_path = "../data/hybrid_dataset"

    # Create directory structure
    for split in ["training", "validation", "evaluation"]:
        os.makedirs(os.path.join(output_path, split, "healthy_food"), exist_ok=True)
        os.makedirs(os.path.join(output_path, split, "non_food"), exist_ok=True)
        os.makedirs(os.path.join(output_path, split, "unhealthy_food"), exist_ok=True)

    # Copy non-food images from Food-5K
    for split in ["training", "validation", "evaluation"]:
        src_dir = os.path.join(food5k_path, split, "non_food")
        dst_dir = os.path.join(output_path, split, "non_food")

        print(f"Copying non-food images from {split} set...")
        for img in os.listdir(src_dir):
            if img.endswith(".jpg"):
                shutil.copy2(os.path.join(src_dir, img), os.path.join(dst_dir, img))

    # Copy and categorize food images from Food-101
    total_images_per_category = 1000  # Adjust this number as needed

    print("\nCopying healthy food images from Food-101...")
    for category in HEALTHY_FOODS:
        category_path = os.path.join(food101_path, category)
        if not os.path.exists(category_path):
            print(f"Warning: Category {category} not found")
            continue

        images = [f for f in os.listdir(category_path) if f.endswith(".jpg")]
        images = images[:total_images_per_category]

        # Calculate split sizes
        num_images = len(images)
        train_size = int(num_images * 0.7)
        val_size = int(num_images * 0.15)

        # Split images
        train_images = images[:train_size]
        val_images = images[train_size : train_size + val_size]
        test_images = images[train_size + val_size :]

        # Copy to respective splits in healthy_food directory
        for split_info in [
            ("training", train_images),
            ("validation", val_images),
            ("evaluation", test_images),
        ]:
            split_name, split_images = split_info
            for img in split_images:
                shutil.copy2(
                    os.path.join(category_path, img),
                    os.path.join(
                        output_path, split_name, "healthy_food", f"{category}_{img}"
                    ),
                )

    print("\nCopying unhealthy food images from Food-101...")
    for category in UNHEALTHY_FOODS:
        # Same process for unhealthy foods
        category_path = os.path.join(food101_path, category)
        if not os.path.exists(category_path):
            print(f"Warning: Category {category} not found")
            continue

        images = [f for f in os.listdir(category_path) if f.endswith(".jpg")]
        images = images[:total_images_per_category]

        num_images = len(images)
        train_size = int(num_images * 0.7)
        val_size = int(num_images * 0.15)

        train_images = images[:train_size]
        val_images = images[train_size : train_size + val_size]
        test_images = images[train_size + val_size :]

        # Copy to respective splits in unhealthy_food directory
        for split_info in [
            ("training", train_images),
            ("validation", val_images),
            ("evaluation", test_images),
        ]:
            split_name, split_images = split_info
            for img in split_images:
                shutil.copy2(
                    os.path.join(category_path, img),
                    os.path.join(
                        output_path, split_name, "unhealthy_food", f"{category}_{img}"
                    ),
                )

    # Print final dataset statistics
    print("\nFinal Dataset Statistics:")
    for split in ["training", "validation", "evaluation"]:
        healthy_count = len(
            os.listdir(os.path.join(output_path, split, "healthy_food"))
        )
        non_food_count = len(os.listdir(os.path.join(output_path, split, "non_food")))
        unhealthy_count = len(
            os.listdir(os.path.join(output_path, split, "unhealthy_food"))
        )
        print(f"\n{split.capitalize()} set:")
        print(f"Healthy food images: {healthy_count}")
        print(f"Non-food images: {non_food_count}")
        print(f"Unhealthy food images: {unhealthy_count}")
        print(f"Total: {healthy_count + non_food_count + unhealthy_count}")


if __name__ == "__main__":
    print("Creating hybrid dataset...")
    create_hybrid_dataset()
    print("\nDone!")

================
File: backend/ml/src/test_api.py
================
# test_api.py
import tensorflow as tf
import numpy as np
from PIL import Image
import os


def load_and_preprocess_image(image_path):
    """Load and preprocess a single image"""
    img = Image.open(image_path)
    img = img.resize((224, 224))
    img_array = np.array(img) / 255.0
    img_array = np.expand_dims(img_array, 0)
    return img_array


def test_images():
    """Test model predictions on test images"""
    # Categories
    CATEGORIES = ["non_food", "food", "junk_food"]

    # Load model
    print("Loading model...")
    model_path = "../model/model_latest.h5"
    try:
        model = tf.keras.models.load_model(model_path)
    except Exception as e:
        print(f"Error loading model: {e}")
        return

    # Test directory
    test_dir = "../test_images"
    test_images = sorted(
        [f for f in os.listdir(test_dir) if f.endswith((".jpg", ".jpeg"))]
    )

    print("\nTesting images...")
    print("=" * 50)

    results = []
    for image_name in test_images:
        image_path = os.path.join(test_dir, image_name)
        try:
            # Process image
            img_array = load_and_preprocess_image(image_path)

            # Get predictions
            predictions = model.predict(img_array, verbose=0)[0]
            predicted_class = np.argmax(predictions)
            confidence = predictions[predicted_class]

            # Store results
            result = {
                "image": image_name,
                "predicted": CATEGORIES[predicted_class],
                "confidence": confidence,
                "probabilities": {
                    cat: float(prob) for cat, prob in zip(CATEGORIES, predictions)
                },
            }
            results.append(result)

            # Print results
            print(f"\nImage: {image_name}")
            print(f"Predicted: {result['predicted']}")
            print(f"Confidence: {confidence:.4f}")
            print("Probabilities:")
            for cat, prob in result["probabilities"].items():
                print(f"  {cat}: {prob:.4f}")
            print("-" * 50)

        except Exception as e:
            print(f"Error processing {image_name}: {e}")

    # Print summary
    print("\nSummary:")
    for category in CATEGORIES:
        count = sum(1 for r in results if r["predicted"] == category)
        print(f"{category}: {count} images")


if __name__ == "__main__":
    test_images()

================
File: backend/ml/src/test_model_webcam.py
================
import tensorflow as tf
import cv2
import numpy as np
import os
import sys


def load_and_preprocess_frame(frame):
    resized = cv2.resize(frame, (224, 224))
    rgb = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)
    normalized = rgb / 255.0
    batched = np.expand_dims(normalized, 0)
    return batched


def main():
    # Load the trained model
    print("Loading model...")
    model_path = "../model_latest.h5"
    if not os.path.exists(model_path):
        print(f"Error: Model not found at {model_path}")
        sys.exit(1)

    model = tf.keras.models.load_model(model_path)

    # Category labels and colors
    CATEGORIES = ["NOT FOOD", "HEALTHY FOOD", "UNHEALTHY FOOD"]
    COLORS = [
        (0, 0, 255),  # Red for NOT FOOD
        (0, 255, 0),  # Green for HEALTHY FOOD
        (0, 165, 255),  # Orange for UNHEALTHY FOOD (BGR format)
    ]

    print("Starting webcam...")
    cap = cv2.VideoCapture(0)

    # Check if camera opened successfully
    if not cap.isOpened():
        print("\nError: Could not open camera")
        print(
            "Please check your camera permissions in System Settings > Privacy & Security > Camera"
        )
        print("Make sure Terminal/Python has permission to access the camera")
        sys.exit(1)

    print("Camera accessed successfully!")
    print("Press 'q' to quit")

    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                print("Failed to grab frame")
                break

            processed_frame = load_and_preprocess_frame(frame)
            predictions = model.predict(processed_frame, verbose=0)[0]
            predicted_class = np.argmax(predictions)
            confidence = predictions[predicted_class]

            # Get all probabilities
            probabilities = {cat: prob for cat, prob in zip(CATEGORIES, predictions)}

            # Prepare text display
            text = CATEGORIES[predicted_class]
            confidence_text = f"Confidence: {confidence:.2f}"

            # Additional probabilities text
            prob_texts = [f"{cat}: {prob:.2f}" for cat, prob in probabilities.items()]

            # Background rectangle for text (make it larger for all probabilities)
            cv2.rectangle(frame, (10, 10), (300, 110), (0, 0, 0), -1)

            # Add main prediction and confidence
            cv2.putText(
                frame,
                text,
                (20, 35),
                cv2.FONT_HERSHEY_SIMPLEX,
                1,
                COLORS[predicted_class],
                2,
            )
            cv2.putText(
                frame,
                confidence_text,
                (20, 60),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.7,
                (255, 255, 255),
                2,
            )

            # Add all probabilities
            y_offset = 85
            cv2.putText(
                frame,
                f"All: {' | '.join(prob_texts)}",
                (20, y_offset),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.4,
                (255, 255, 255),
                1,
            )

            cv2.imshow("Food Detector", frame)

            if cv2.waitKey(1) & 0xFF == ord("q"):
                print("\nQuitting...")
                break

    except KeyboardInterrupt:
        print("\nInterrupted by user")
    except Exception as e:
        print(f"\nAn error occurred: {str(e)}")
    finally:
        cap.release()
        cv2.destroyAllWindows()


if __name__ == "__main__":
    main()

================
File: backend/ml/src/test_model.py
================
# test_model.py
import tensorflow as tf
import numpy as np
from PIL import Image
import os
import random


def load_and_preprocess_image(image_path):
    # Load image
    img = Image.open(image_path)
    # Resize to match model's expected input
    img = img.resize((224, 224))
    # Convert to array and normalize
    img_array = np.array(img) / 255.0
    # Add batch dimension
    img_array = np.expand_dims(img_array, 0)
    return img_array


def test_model():
    # Load the trained model
    print("Loading model...")
    model = tf.keras.models.load_model("../model_final.h5")

    # Print model summary
    print("\nModel Summary:")
    model.summary()

    # Paths for evaluation set
    eval_dir = "../data/hybrid_dataset/evaluation"
    healthy_food_dir = os.path.join(eval_dir, "healthy_food")
    non_food_dir = os.path.join(eval_dir, "non_food")
    unhealthy_food_dir = os.path.join(eval_dir, "unhealthy_food")

    # Get 5 random images from each category
    healthy_food_images = random.sample(
        [f for f in os.listdir(healthy_food_dir) if f.endswith(".jpg")], 5
    )
    non_food_images = random.sample(
        [f for f in os.listdir(non_food_dir) if f.endswith(".jpg")], 5
    )
    unhealthy_food_images = random.sample(
        [f for f in os.listdir(unhealthy_food_dir) if f.endswith(".jpg")], 5
    )

    categories = ["Non-Food", "Healthy Food", "Unhealthy Food"]

    def test_category(images, directory, category_name):
        print(f"\nTesting {category_name} Images:")
        print("=" * 50)
        for img_name in images:
            img_path = os.path.join(directory, img_name)
            img_array = load_and_preprocess_image(img_path)
            predictions = model.predict(img_array, verbose=0)[0]

            predicted_class = np.argmax(predictions)
            confidence = predictions[predicted_class]

            print(f"\nImage: {img_name}")
            print(f"Prediction: {categories[predicted_class]}")
            print(f"Confidence: {confidence:.4f}")
            print("All probabilities:")
            for cat, prob in zip(categories, predictions):
                print(f"  {cat}: {prob:.4f}")
            print("-" * 50)

    # Test all categories
    test_category(healthy_food_images, healthy_food_dir, "Healthy Food")
    test_category(non_food_images, non_food_dir, "Non-Food")
    test_category(unhealthy_food_images, unhealthy_food_dir, "Unhealthy Food")


if __name__ == "__main__":
    print("Testing model on all three categories...")
    test_model()

================
File: backend/ml/src/train.py
================
# train.py
import tensorflow as tf
from tensorflow.keras import layers, models
from dataset import FoodDataset
import os
import shutil


def ensure_directories():
    """Create necessary directories for model saving"""
    # Create both src/checkpoints and checkpoints directories
    directories = ["checkpoints", "src/checkpoints"]
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
        print(f"Created directory: {directory}")


def save_model_with_verification(model, base_path, filename):
    """Save model and verify it exists in both locations"""
    # Save to primary location
    primary_path = os.path.join(base_path, filename)
    model.save(primary_path)
    print(f"Model saved to: {primary_path}")

    # Copy to src/checkpoints for compatibility
    src_path = os.path.join("src/checkpoints", filename)
    shutil.copy2(primary_path, src_path)
    print(f"Model copied to: {src_path}")

    return primary_path, src_path


def train():
    # Configuration
    DATA_DIR = "../data/hybrid_dataset"
    IMG_SIZE = (224, 224)
    BATCH_SIZE = 32
    EPOCHS = 15

    # Ensure directories exist
    ensure_directories()

    print(f"Loading data from: {os.path.abspath(DATA_DIR)}")

    # Create datasets
    dataset = FoodDataset(DATA_DIR, IMG_SIZE, BATCH_SIZE)
    train_ds = dataset.create_dataset("training")
    val_ds = dataset.create_dataset("validation")

    # Get class weights
    class_weights = dataset.get_class_weights("training")
    print("\nClass weights:", class_weights)

    # Create model
    print("\nCreating model...")
    model = models.Sequential(
        [
            tf.keras.applications.MobileNetV2(
                input_shape=(*IMG_SIZE, 3), include_top=False, weights="imagenet"
            ),
            layers.GlobalAveragePooling2D(),
            layers.Dense(256, activation="relu"),
            layers.Dropout(0.4),
            layers.Dense(128, activation="relu"),
            layers.Dropout(0.3),
            layers.Dense(3, activation="softmax"),
        ]
    )

    # Compile model
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
        loss="categorical_crossentropy",
        metrics=["accuracy"],
    )

    # Callbacks
    callbacks = [
        tf.keras.callbacks.ModelCheckpoint(
            filepath="checkpoints/best_model.h5",
            save_best_only=True,
            monitor="val_accuracy",
            mode="max",
            verbose=1,
        ),
        tf.keras.callbacks.EarlyStopping(
            monitor="val_accuracy", patience=5, restore_best_weights=True
        ),
        tf.keras.callbacks.ReduceLROnPlateau(
            monitor="val_loss", factor=0.2, patience=3, min_lr=1e-6
        ),
    ]

    # Train model
    print("\nStarting training...")
    history = model.fit(
        train_ds,
        validation_data=val_ds,
        epochs=EPOCHS,
        callbacks=callbacks,
        class_weight=class_weights,
        verbose=1,
    )

    # Save final model with verification
    print("\nSaving final model...")
    try:
        primary_path, src_path = save_model_with_verification(
            model, "checkpoints", "model.h5"
        )
        print(f"Model successfully saved and verified at:")
        print(f"1. {primary_path}")
        print(f"2. {src_path}")
    except Exception as e:
        print(f"Error saving model: {str(e)}")

    return history, model


if __name__ == "__main__":
    print("Starting training process...")
    try:
        history, model = train()

        # Verify saved model exists
        expected_paths = ["checkpoints/model.h5", "src/checkpoints/model.h5"]
        for path in expected_paths:
            if os.path.exists(path):
                print(f"Verified: Model exists at {path}")
            else:
                print(f"Warning: Model not found at {path}")

    except Exception as e:
        print(f"Error during training: {str(e)}")

================
File: backend/ml/requirements.txt
================
tensorflow-macos
tensorflow-metal
flask
pillow
flask-cors
numpy
scikit-learn

================
File: backend/models/user.ts
================
import Joi from "joi";
import mongoose from "mongoose";
import jwt from "jsonwebtoken";

interface IUserDocument extends mongoose.Document {
  firstName: string;
  lastName: string;
  email: string;
  password: string;
  petName: string;
  healthPoints: number;
  mood: "happy" | "sad" | "neutral";
  generateAuthToken(): string;
}

const userSchema = new mongoose.Schema<IUserDocument>({
  firstName: {
    type: String,
    required: true,
    maxlength: 50,
  },
  lastName: {
    type: String,
    required: true,
    maxlength: 50,
  },
  email: {
    type: String,
    required: true,
    minlength: 5,
    maxlength: 255,
    unique: true,
  },
  password: {
    type: String,
    required: true,
    minlength: 5,
    maxlength: 1024,
  },
  petName: {
    type: String,
    required: true,
    minlength: 1,
    maxlength: 255,
  },
  healthPoints: {
    type: Number,
    default: 100,
  },
  mood: {
    type: String,
    enum: ["happy", "sad", "neutral"],
    default: "neutral",
  },
});

userSchema.methods.generateAuthToken = function () {
  const token = jwt.sign(
    {
      _id: this._id,
      firstName: this.firstName,
      lastName: this.lastName,
      role: "user",
    },
    process.env.JWT_PRIVATE_KEY || "this is a secret key"
  );
  return token;
};

export const User = mongoose.model("users", userSchema);

export function validateUser(user) {
  const schema = Joi.object({
    firstName: Joi.string().max(50).required(),
    lastName: Joi.string().max(50).required(),
    email: Joi.string().min(5).max(255).required().email(),
    password: Joi.string().min(5).max(255).required(),
    petName: Joi.string().min(1).max(255).required(),
  });
  return schema.validate(user);
}

================
File: backend/repos/foodRepo.ts
================
import multer from 'multer';
import path from 'path';
import fs from 'fs';
import { Express } from 'express';  // for type definitions

// 1. Configure the storage destination for uploaded files

const __dirname = path.resolve();
const storage = multer.diskStorage({
  destination: function (_req, _file, cb) {
    // Construct path to the ml/uploads folder
    console.log(__dirname);
    const uploadPath = path.join(__dirname, '/ml/uploads');
    // Ensure folder exists
    if (!fs.existsSync(uploadPath)) {
      fs.mkdirSync(uploadPath, { recursive: true });
    }
    cb(null, uploadPath);
  },
  filename: function (_req, file, cb) {
    // Optional unique suffix to avoid collisions
    const uniqueSuffix = Date.now() + '-' + Math.round(Math.random() * 1e9);
    cb(null, uniqueSuffix + '-' + file.originalname);
  }
});

// 2. Create a Multer instance using the above storage config
const upload = multer({ storage });

// 3. Export the single file upload middleware
//    This can be used in your route: app.post(..., singleFoodUpload, ...)
export const singleFoodUpload = upload.single('photo');

// 4. Example: Additional processing or business logic
//    Called AFTER multer has saved the file
export function processFoodFile(file: Express.Multer.File) {
  // Here you could do any additional logic, such as:
  // - log to a database
  // - call an AI model
  // - rename the file further
  // - etc.

  // We'll just return a simple message here
  return {
    message: 'Image received and saved successfully!',
    filename: file.filename,
    path: file.path
  };
}

================
File: backend/repos/stateRepo.ts
================
import {User} from "../models/user";

export const getStates = async (req, res) => {
  const userId = process.env.DEMO_USER_ID;
  const user = await User.findById(userId);
  if (!user) return res.status(404).json({error: "User not found."});
  return res.status(200).json({HP: user.healthPoints, mood: user.mood});
};

================
File: backend/repos/userRepo.ts
================
import {User, validateUser} from "../models/user.js";
import Joi from "joi";
import bcrypt from "bcryptjs";
const {hash, genSalt, compare} = bcrypt;
import _ from "lodash";

export const login = async (req, res) => {
  const {error} = validate(req.body);
  if (error) return res.status(400).json({error: error.details[0].message});

  let user = await User.findOne({email: req.body.email});
  if (!user) return res.status(400).json({error: "Invalid email or password."});

  if (!user.password)
    return res.status(400).json({error: "Invalid email or password."});

  const validPassword = await compare(req.body.password, user.password);
  if (!validPassword)
    return res.status(400).json({error: "Invalid email or password."});

  const token = user.generateAuthToken();

  res.status(200).json({
    message: "Login successful",
    token,
    user: {
      _id: user._id,
      email: user.email,
      firstName: user.firstName,
      lastName: user.lastName,
      petName: user.petName,
    },
  });
};

export const register = async (req, res) => {
  const {error} = validateUser(req.body);
  if (error) return res.status(400).send(error.details[0].message);

  let user = await User.findOne({email: req.body.email});
  if (user) return res.status(400).send("User already registered.");

  user = new User(
    _.pick(req.body, ["firstName", "lastName", "email", "password", "petName"])
  );
  const salt = await genSalt(10);
  user.password = await hash(user.password, salt);
  await user.save();

  const token = user.generateAuthToken();
  res
    .header("x-auth-token", token)
    .send(_.pick(user, ["_id", "firstName", "lastName", "email", "petName"]));

  return res.status(201).json({
    message: "Registration successful",
    token,
    user: _.pick(user, ["_id", "firstName", "lastName", "email", "petName"]),
  });
};

function validate(req) {
  const schema = {
    email: Joi.string().min(5).max(255).required().email(),
    password: Joi.string().min(5).max(255).required(),
  };

  return Joi.object(schema).validate(req.body);
}

export const test = (req, res) => {
  return res.status(200).json({message: "Test route"});
};

================
File: backend/routes/auth.ts
================
import {auth} from "./../middleware/auth";
import express from "express";
import {login, register, test} from "../repos/userRepo";

const router = express.Router();

router.post("/", login);
router.post("/register", register);
router.get("/test", auth, test);

export default router;

================
File: backend/routes/food.ts
================
import { Router, Request, Response } from 'express';
import { singleFoodUpload, processFoodFile } from '../repos/foodRepo'; 
// adjust path if needed

const router = Router();

// POST /food
router.post('/', singleFoodUpload, (req: Request, res: Response) => {
  try {
    // Multer has already processed the file at this point
    if (!req.file) {
      return res.status(400).json({ error: 'No file uploaded.' });
    }

    // Perform any post-processing logic
    const result = processFoodFile(req.file);

    // Send result back to the client
    return res.json(result);

  } catch (error) {
    console.error('Error in /food route:', error);
    return res.status(500).json({ error: 'Internal server error.' });
  }
});

export default router;

================
File: backend/routes/ml.ts
================
import express, { Request, Response } from "express";
import { spawn } from "child_process";
import path from "path";
import multer from "multer";
import { fileURLToPath } from "url";
import fs from "fs/promises";

// Types
interface ClassificationResult {
  category: string;
  confidence: number;
  all_probabilities: {
    [key: string]: number;
  };
}

interface ErrorResponse {
  error: string;
  details?: unknown;
}

// Configuration
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Multer configuration with file filtering and size limits
const storage = multer.diskStorage({
  destination: "uploads/",
  filename: (req, file, cb) => {
    const uniqueSuffix = `${Date.now()}-${Math.round(Math.random() * 1e9)}`;
    cb(null, `${uniqueSuffix}-${file.originalname}`);
  },
});

const fileFilter = (
  req: Express.Request,
  file: Express.Multer.File,
  cb: multer.FileFilterCallback
) => {
  const allowedTypes = ["image/jpeg", "image/png", "image/jpg"];

  if (allowedTypes.includes(file.mimetype)) {
    cb(null, true);
  } else {
    cb(new Error("Invalid file type. Only JPEG and PNG are allowed."));
  }
};

const upload = multer({
  storage,
  fileFilter,
  limits: {
    fileSize: 5 * 1024 * 1024, // 5MB limit
  },
});

const router = express.Router();

// Helper function to run Python script
const runPythonScript = async (
  scriptPath: string,
  args: string[] = []
): Promise<string> => {
  return new Promise((resolve, reject) => {
    const pythonProcess = spawn("python", [scriptPath, ...args]);
    let result = "";
    let errorOutput = "";

    pythonProcess.stdout.on("data", (data) => {
      result += data.toString();
    });

    pythonProcess.stderr.on("data", (data) => {
      errorOutput += data.toString();
    });

    pythonProcess.on("close", (code) => {
      if (code === 0) {
        resolve(result);
      } else {
        reject(
          new Error(`Python script failed with code ${code}: ${errorOutput}`)
        );
      }
    });

    pythonProcess.on("error", (error) => {
      reject(error);
    });
  });
};

// Cleanup function for uploaded files
const cleanupFile = async (filePath: string): Promise<void> => {
  try {
    await fs.unlink(filePath);
  } catch (error) {
    console.error(`Failed to cleanup file ${filePath}:`, error);
  }
};

// Routes
router.post(
  "/predict",
  upload.single("image"),
  async (
    req: Request,
    res: Response<ClassificationResult | ErrorResponse>
  ): Promise<void> => {
    if (!req.file) {
      res.status(400).json({ error: "No image provided" });
      return;
    }

    try {
      const result = await runPythonScript(
        path.join(__dirname, "../ml/src/api.py"),
        [req.file.path]
      );

      const classification: ClassificationResult = JSON.parse(result);
      res.json(classification);
    } catch (error) {
      console.error("Classification error:", error);
      res.status(500).json({
        error: "Classification failed",
        details: error instanceof Error ? error.message : String(error),
      });
    } finally {
      // Cleanup uploaded file
      if (req.file) {
        await cleanupFile(req.file.path);
      }
    }
  }
);

router.get(
  "/training-info",
  async (req: Request, res: Response): Promise<void> => {
    try {
      const result = await runPythonScript(
        path.join(__dirname, "../ml/src/test_api.py")
      );

      const info = JSON.parse(result);
      res.json(info);
    } catch (error) {
      console.error("Training info error:", error);
      res.status(500).json({
        error: "Could not get training info",
        details: error instanceof Error ? error.message : String(error),
      });
    }
  }
);

// Error handling middleware
router.use(
  (error: Error, req: Request, res: Response, next: express.NextFunction) => {
    console.error("ML Router Error:", error);

    if (error instanceof multer.MulterError) {
      if (error.code === "LIMIT_FILE_SIZE") {
        res
          .status(400)
          .json({ error: "File size is too large. Maximum size is 5MB." });
      } else {
        res.status(400).json({ error: error.message });
      }
    } else {
      res.status(500).json({ error: "Internal server error" });
    }
  }
);

export default router;

================
File: backend/routes/state.ts
================
import {auth} from "./../middleware/auth";
import express from "express";
import {login, register, test} from "../repos/userRepo";
import { getStates } from "../repos/stateRepo";

const router = express.Router();

router.get("/", getStates);

export default router;

================
File: backend/startup/db.ts
================
import mongoose from "mongoose";

const uri = process.env.MONGO_URI;

if (!uri) {
  console.error("MONGODB_URI is not defined.");
  process.exit(1);
}

export async function connectToMongo() {
  try {
    await mongoose.connect(uri || "");
    console.log("Connected to MongoDB using Mongoose");
  } catch (err) {
    console.error("Error connecting to MongoDB with Mongoose:", err);
  }
}

================
File: backend/startup/routes.ts
================
import authRoutes from "../routes/auth.js";
import stateRoutes from "../routes/state.js";
import foodRoutes from "../routes/food.js";
const setupRoutes = (app) => {
  app.use("/api/auth", authRoutes);
  app.use("/api/state", stateRoutes);
  app.use("/api/food", foodRoutes);
};

export default setupRoutes;

================
File: backend/.gitignore
================
# Create a comprehensive .gitignore in project root
cat > .gitignore << 'EOL'
# Dependencies
/node_modules
**/node_modules

# Python
**/__pycache__
*.py[cod]
*.$py.class

# Virtual Environment - Specific paths
/backend/ml/venv
/backend/ml/venv/
/backend/ml/venv/*
**/venv
**/.venv

# Build artifacts
/dist
/build
*.egg-info

# Environment files
.env
.env.local
.env.*

# IDE
.vscode
.idea
*.swp
*.swo

# OS
.DS_Store
Thumbs.db

# Project specific
/backend/uploads

# Debug logs
npm-debug.log*
yarn-debug.log*
yarn-error.log*
EOL

================
File: backend/index.ts
================
import dotenv from "dotenv";
dotenv.config();

import {connectToMongo} from "./startup/db.js";
import express from "express";
import setupRoutes from "./startup/routes.js";
import cors from "cors";

console.log(process.env.MONGO_URI);
console.log(process.env.FRONTEND_URL);
console.log(process.env.PORT);

const app = express();
const port = process.env.PORT || 4000;

// Enable CORS for frontend
app.use(
  cors({
    origin: process.env.FRONTEND_URL,
  })
);

// Connect to MongoDB
// connectToMongo();
app.use(express.json());

// Setup Routes
setupRoutes(app);

// Default Route
app.get("/", (req, res) => {
  res.send(`Hello, World!`);
});

// Start the Server
app.listen(port, () => {
  connectToMongo();
  console.log(`Server is running on http://localhost:${port}`);
});

================
File: backend/package.json
================
{
  "name": "backend",
  "version": "1.0.0",
  "main": "index.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1",
    "dev": "nodemon --watch . --ext ts --exec 'tsx --require dotenv/config index.ts'"
  },
  "author": "",
  "license": "ISC",
  "description": "",
  "type": "module",
  "dependencies": {
    "@paralleldrive/cuid2": "^2.2.2",
    "bcryptjs": "^2.4.3",
    "cloudinary": "^2.5.1",
    "cookie-parser": "^1.4.7",
    "cors": "^2.8.5",
    "dotenv": "^16.4.7",
    "express": "^4.21.0",
    "express-session": "^1.18.1",
    "joi": "^17.13.3",
    "jsonwebtoken": "^9.0.2",
    "lodash": "^4.17.21",
    "mongodb": "^6.9.0",
    "multer": "^1.4.5-lts.1"
  },
  "devDependencies": {
    "@types/express": "^5.0.0",
    "@types/jsonwebtoken": "^9.0.7",
    "@types/lodash": "^4.17.13",
    "@types/mongoose": "^5.11.97",
    "@types/node": "^22.10.1",
    "nodemon": "^3.1.9",
    "ts-node": "^10.9.2",
    "tsx": "^4.19.2",
    "typescript": "^5.7.3"
  }
}

================
File: .gitignore
================
# Create/modify .gitignore in project root
cat > .gitignore << 'EOL'
# Dependencies
/node_modules
**/node_modules
node_modules/

# Build outputs
/dist
/build
/.next
/out

# Environment files
.env
.env.local
.env.*
!.env.example

# IDE
/.idea
/.vscode
*.swp
*.swo

# Debug logs
npm-debug.log*
yarn-debug.log*
yarn-error.log*
.pnpm-debug.log*

# Testing
/coverage

# Production
/build

# Misc
.DS_Store
*.pem
Thumbs.db

# Python
**/__pycache__
*.py[cod]
*.$py.class
/backend/ml/venv
**/venv
**/.venv

# Project specific
/uploads

# TypeScript
*.tsbuildinfo
next-env.d.ts
EOL

================
File: package.json
================
{
  "dependencies": {
    "express": "^4.21.2",
    "multer": "^1.4.5-lts.1"
  },
  "devDependencies": {
    "@types/express": "^5.0.0",
    "@types/multer": "^1.4.12",
    "@types/node": "^22.13.4",
    "typescript": "^4.5.4"
  }
}

================
File: README.md
================
1. Copy .env to the server folder
2. Run `python -m venv venv`
3. Run `source venv/bin/activate`
4. Run `pip install -r requirements.txt`

================
File: setup.sh
================
#!/bin/bash

# Install Node.js dependencies
npm install

# Setup backend
cd backend
npm install

# Setup ML environment
cd ml
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
cd ../..

echo "Setup complete!"
